{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис: теперь пользователи могут сами редактировать и дополнять описания товаров. Необходимо разработать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "### Метрики\n",
    "\n",
    "*F1* > 0,75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка среды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from IPython.display import display as d\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим среду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "r_state = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL-адрес модели *BERT*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conversational_cased_L-12_H-768_A-12_pt\n",
    "\n",
    "http://files.deeppavlov.ai/deeppavlov_data/bert/conversational_cased_L-12_H-768_A-12_pt.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function removes unnecessary spaces\n",
    "\n",
    "def space_reduction(corpus):\n",
    "    for i in range(len(corpus)):\n",
    "        corpus[i] = corpus[i].split()\n",
    "        corpus[i] = ' '.join(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function counts the difference between the balances of classes of the original and the current sample\n",
    "\n",
    "def class_ratio_control(df, test_size=1/6, precision=0.95):\n",
    "    original = df.target[df.target == 1].count() / \\\n",
    "               df.target[df.target == 0].count()\n",
    "\n",
    "    while True:\n",
    "        index_train, index_test = train_test_split(df.index.values, test_size=test_size)\n",
    "        \n",
    "        train = df.loc[index_train, 'target'][df.target == 1].count() / \\\n",
    "                df.loc[index_train, 'target'][df.target == 0].count()\n",
    "\n",
    "        test = df.loc[index_test, 'target'][df.target == 1].count() / \\\n",
    "               df.loc[index_test, 'target'][df.target == 0].count()\n",
    "        \n",
    "        if ( (precision < train/original < 1/precision) and (precision < test/original < 1/precision) ):\n",
    "            print('ratio of the classes:\\noriginal: {:.4f}\\ntrain:    {:.4f}\\ntest:     {:.4f}\\n'\n",
    "                  .format(original, train, test)\n",
    "                 )\n",
    "            return index_train, index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function computes indexes of the train and the validation sample for cross-validation\n",
    "\n",
    "def cv_indexes(index_train_valid, cv=3, valid_size=0.2):\n",
    "    valid_size_loc = valid_size\n",
    "    if cv * valid_size > 1.0:\n",
    "        valid_size_loc = 0.98 / cv\n",
    "\n",
    "    index_train = []\n",
    "    index_valid = []\n",
    "\n",
    "    for i in range(cv):\n",
    "        bounds = [\n",
    "            int(len(index_train_valid) * valid_size_loc * i),\n",
    "            int(len(index_train_valid) * valid_size_loc * (i+1))\n",
    "        ]\n",
    "\n",
    "        if bounds[1] > len(index_train_valid):\n",
    "            bounds[1] = len(index_train_valid)\n",
    "\n",
    "        index_train.append(np.concatenate((index_train_valid[:bounds[0]],\n",
    "                                           index_train_valid[bounds[1]:]),\n",
    "                                          axis=0\n",
    "                                         )\n",
    "                          )\n",
    "        index_valid.append(index_train_valid[bounds[0]:bounds[1]])\n",
    "    \n",
    "    return index_train, index_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function replaces embeddings (or tokens) longer than max_pos by zeros\n",
    "\n",
    "def position_embeddings_filter(x, max_pos):\n",
    "    if len(x) > max_pos:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The func takes a sample from the data passed\n",
    "\n",
    "def sample_func(df, n_samples, target_col_name, frac_one, return_index=False):\n",
    "    data_1 = df[df[target_col_name] == 1].sample(n=int(n_samples * frac_one), random_state=r_state)\n",
    "    data_0 = df[df[target_col_name] == 0].sample(n=int(n_samples - data_1.shape[0]), random_state=r_state)\n",
    "    data = data_1.append(data_0).sample(frac=1, random_state=r_state)\n",
    "    \n",
    "    if return_index:\n",
    "        return data.index\n",
    "    else:\n",
    "        return data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ознакомление с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл открылся корректно, пропусков в данных нет.\n",
    "\n",
    "Проверим целевой признак на наличие дисбаланса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется дисбаланс целевого признака. Будем это учитывать.\n",
    "\n",
    "Найдём долю положительного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167887648758234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_class_1 = data_raw.toxic[data_raw.toxic == 1].count() / data_raw.toxic.count()\n",
    "frac_class_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование корпуса текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем корпус текстов. Для этого приведём значения столбца *text* к типу данных *Unicode* и сохраним массив с ними в отдельной переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "corp_raw = data_raw.text.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка корпуса текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вводная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с текстами под созданием признаков понимается преобразование текстов в векторы. Мы будем это делать двумя алгоритмами:\n",
    "\n",
    "* *TF-IDF*;\n",
    "* *BERT*.\n",
    "\n",
    "Эти два алгоритма сильно различаются между собой. В первом случае требуется предобработка текстов, а затем алгоритм преобразования необходимо обучить (причём делать это придётся не однократно, а множество раз в ходе кросс-валидации). Второй подход предполагает использование заранее обученной модели (признаки сформируем однократно уже в данном разделе) и отсутствие необходимости в лемматизации текста (потребуется лишь базовая предобработка).\n",
    "\n",
    "В данном разделе сначала выполним базовую предобработку корпуса текстов, необходимую для обоих алгоритмов. Затем - подготовим корпус для использования в *TF-IDF*. После этого - сформируем признаки с помощью алгоритма *BERT*.\n",
    "\n",
    "Корпус текстов для *TF-IDF* будет называться ***corp_lemm*** (так как будет выполнена в том числе лемматизация), а для *BERT* - ***corp*** (будет выполнена только очистка от небуквенных символов и лишних пробелов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка, токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим корпус от небуквенных символов при помощи регулярных выражений, удалим стоп-слова (слова, не несущие смысловой нагрузки: предлоги, частицы и т.п.) и выполним токенизацию - разбиение текста на отдельные слова. Токенизация необходима для корректной работы алгоритма *WordNetLemmatizer* библиотеки *nltk*, при помощи которого будет выполняться лемматизация. Токенизация и удаление стоп-слов будут выполнены средствами библиотеки *nltk*.\n",
    "\n",
    "Удаление стоп-слов перед выполнением токенизации (и, соответственно, лемматизации) обусловлено следующими причинами.\n",
    "* Токенизация, как оказалось, искажает некоторые стоп-слова таким образом, что они не будут распознаны. Например: \"weren't\" превращается в \"were\" и \"n't\". Первое - удалится (т.к. есть в списке), а второе - останется.\n",
    "* Сократится машинное время на разметку частей речи - самую ресурсоёмкую операцию - благодаря уменьшению количества слов в корпусе.\n",
    "\n",
    "Загрузим словать стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Андрей\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список стоп-слов с пробелами в начале и в конце, чтобы можно было отыскать в тексте корпуса стоп-слова как отдельные слова, а не как составные части других слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' themselves ', ' yourselves ', ' ourselves ', \" should've \", \" shouldn't \"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_with_spaces = [''] * len(stop_words)\n",
    "stop_words_list = list(stop_words)\n",
    "\n",
    "for i in range(len(stop_words_with_spaces)):\n",
    "    stop_words_with_spaces[i] = f' {stop_words_list[i]} '\n",
    "\n",
    "stop_words_with_spaces.sort(key=len, reverse=True)\n",
    "stop_words_with_spaces[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим две переменные, в которые поместим корпусы текстов до и после лемматизации (соответственно *corp* и *corp_lemm*).\n",
    "\n",
    "Выполним очистку от небуквенных символов (для обоих массивов), удаление стоп-слов, токенизацию (только для *corp_lemm*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94f96b410914fbd9fcae1af9e79d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "corp = [''] * len(corp_raw)\n",
    "corp_lemm = corp.copy()\n",
    "\n",
    "for i in notebook.tqdm(range(len(corp_raw))):\n",
    "    corp[i] = re.sub(r'[^a-zA-Z\\' ]', ' ', corp_raw[i])\n",
    "    corp_lemm[i] = corp[i].lower()\n",
    "\n",
    "    for sw in stop_words_with_spaces:\n",
    "        if (sw in corp_lemm[i]) == True:\n",
    "            corp_lemm[i] = corp_lemm[i].replace(sw, ' ')\n",
    "        if corp_lemm[i].startswith(sw[1:],) == True:\n",
    "            corp_lemm[i] = corp_lemm[i][len(sw[1:]):]\n",
    "        if corp_lemm[i].endswith(sw[:-1]) == True:\n",
    "            corp_lemm[i] = corp_lemm[i][:-len(sw[:-1])]\n",
    "\n",
    "    \n",
    "    corp_lemm[i] = nltk.word_tokenize(corp_lemm[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим исходный корпус текстов (он больше не потребуется), чтобы освободить память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corp_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем, к какой части речи относится каждое слово корпуса, при помощи метода *pos_tag_sents*. Это необходимо для корректного выполнения лемматизации. По умолчанию алгоритм *WordNetLemmatizer* воспринимает все слова как существительные, а потом \"не знает\", что делать со словами, которые существительными по факту не являются. Поэтому требуется явное указание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "corp_tagged = nltk.pos_tag_sents(corp_lemm, tagset='universal', lang='eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним лемматизацию.\n",
    "\n",
    "Несколько странно, что в рамках одной библиотеки функция возвращает результат в формате, не подходящем для его подачи на вход другой функции, для которой этот результат главным образом предназначался. Такая ситуация - с тегами, обозначающими часть речи. Чтобы решить эту проблему, выполним небольшое преобразование (возьмём только первый символ тега и приведём его к нижнему регистру). В случае подачи несовместимого тега (да, такое здесь встречается) установим тег \"существительное\" ('n') в ветке исключения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wnl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e922e0d51be74906b4d218a1822a9a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in notebook.tqdm(range(len(corp_tagged))):\n",
    "    corp_lemm[i] = ''\n",
    "    for x in range(len(corp_tagged[i])):\n",
    "        try:\n",
    "            lemma = wnl.lemmatize(corp_tagged[i][x][0], corp_tagged[i][x][1][0].lower())\n",
    "        except:\n",
    "            lemma = wnl.lemmatize(corp_tagged[i][x][0], 'n')\n",
    "        corp_lemm[i] += f' {lemma}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим корпус текстов, дополненный тегами pos (он больше не потребуется), чтобы освободить память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corp_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление лишних пробелов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим лишние пробелы с помощью функции *space_reduction*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "space_reduction(corp)\n",
    "space_reduction(corp_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры очищенных текстов до и после лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There is no reason to treat AFF and SF the same The neutrality policy which explicitly states that it is not to be confused with all views deserve equal time no matter how many or how few people hold them certainly requires nothing of the sort look it up yourself I won t do your homework for you Moreover the merits of AFF and the merits of SF are two entirely separate and independent things No amount of slamming AFF even if your charges are accurate which I doubt as your behaviour here strongly suggests your perceptions on such things cannot be trusted can ever by itself make SF worth including SF must stand or fall on its own merits There are many serious strikes against including SF none of which you have even tried to address First of all it borders on being a blog which is already an almost decisive point against it there was talk of banning links to blogs entirely at one point though it isn t actually policy to do so as far as I know certainly it s a blog has stood uncontested as sufficient reason for deleting links on many pages including the same one we re fighting over Equally importantly having read parts of SF though I do not myself agree with the characterization I can see why others have gone so far as to call it a hate site To be blunt it's largely the chronicle of one person's persecution complex As I said elsewhere it verges on conspiracy theory in the kookiest sense And then there is the painfully bad prose and screechy hysterical tone most of it is written in it is simply not in any way a quality site and would not be even if I could credit the actual content These three points heck any two of them are sufficient reason leave the link off Wikipedia And I haven t even mentioned the most important reason yet Your site simply is not notable As far as I can honestly tell you are the only person on Earth who considers it an important site If it was worth linking to someone other than the site's owner would have done so by now or at least spoken up in favour of such That last part at least is well documented Wikipedia policy look it up yourself as I once again refuse to do your homework for you I am sorry sort of if some of this comes across as harsh Though you will no doubt characterize this note as a personal attack it is not intended as such and compared to some of the things you ve posted about others including me it s not even close to qualifying as one I wish only to lay out as clearly as possible why there is little hope of SF being linked from that or any other Wikipedia page\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"reason treat aff sf neutrality policy explicitly state confused view deserve equal time matter many people hold certainly require nothing sort look homework moreover merit aff merit sf two entirely separate independent thing amount slam aff even charge accurate doubt behaviour strongly suggest perception thing can not trust ever make sf worth include sf must stand fall merit many serious strike include sf none even try address first border blog already almost decisive point talk ban link blog entirely one point though actually policy far know certainly blog stand uncontested sufficient reason delete link many page include one fight equally importantly read part sf though agree characterization see others go far call hate site blunt largely chronicle one person 's persecution complex say elsewhere verge conspiracy theory kooky sense painfully bad prose screechy hysterical tone write simply way quality site would even could credit actual content three point heck two sufficient reason leave link wikipedia even mention important reason yet site simply notable far honestly tell person earth considers important site worth link someone site 's owner would do least spoken favour last part least well documented wikipedia policy look refuse homework sorry sort come across harsh though doubt characterize note personal attack intend compare thing post others include even close qualify one wish lay clearly possible little hope sf link wikipedia page\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(corp[11111])\n",
    "d(corp_lemm[11111])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка корпуса текстов завершена: на основе исходного созданы два очищенных корпуса: с лемматизированными и нелемматизированными текстами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование датафрейма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датафрейм, чтобы избежать проблем с индексацией разрозненных массивов. Перед этим убедимся, что длины корпусов текстов и длина столбца с классом совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corp) == len(corp_lemm) == len(data_raw.toxic.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp</th>\n",
       "      <th>corp_lemm</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>explanation edits make username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww He matches this background colour I'm se...</td>\n",
       "      <td>d'aww match background colour i 'm seemingly s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man I'm really not trying to edit war It's...</td>\n",
       "      <td>hey man i 'm really try edit war guy constantl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More I can't make any real suggestions on impr...</td>\n",
       "      <td>ca n't make real suggestion improvement wonder...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>sir hero chance remember page that 's</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                corp  \\\n",
       "0  Explanation Why the edits made under my userna...   \n",
       "1  D'aww He matches this background colour I'm se...   \n",
       "2  Hey man I'm really not trying to edit war It's...   \n",
       "3  More I can't make any real suggestions on impr...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                           corp_lemm  target  \n",
       "0  explanation edits make username hardcore metal...       0  \n",
       "1  d'aww match background colour i 'm seemingly s...       0  \n",
       "2  hey man i 'm really try edit war guy constantl...       0  \n",
       "3  ca n't make real suggestion improvement wonder...       0  \n",
       "4              sir hero chance remember page that 's       0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=None,\n",
    "                    columns=['corp', 'corp_lemm', 'target']\n",
    "                   )\n",
    "\n",
    "data['corp'] = corp\n",
    "data['corp_lemm'] = corp_lemm\n",
    "data['target'] = data_raw.toxic.values\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TF-IDF* - это условное название алгоритма создания признаков. Алгоритм аналогичен *Мешку слов*. Название же - условное потому, что на самом деле *TF-IDF* - это метрика оценки важности каждого слова в корпусе текстов: важность слова зависит от частоты его употребления в тексте, а также от количества других текстов корпуса, где это слово встречается ещё.\n",
    "\n",
    "Алгоритм предполагает работу с лемматизированными текстами.\n",
    "\n",
    "Поскольку при обучении моделей необходимо применять кросс-валидацию, а векторизация (преобразование текстов в векторы), в свою очередь, тоже предполагает обучение, необходимо выполнять её (векторизацию) на каждом этапе кросс-валидации на соответствующей обучающей выборке. Векторизацию валидационной выборки следует выполнять уже обученным алгоритмом (на каждом этапе - обученным заново).\n",
    "\n",
    "Векторизацию корпуса текстов будем выполнять при помощи функции *TfidfVectorizer* библиотеки *scikit-learn*.\n",
    "\n",
    "Инициализируем счётчик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем путь к модели на диске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/py/bert/conversational_cased_L-12_H-768_A-12_pt/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'pytorch_model.bin'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_path = 'D:/py/bert/conversational_cased_L-12_H-768_A-12_pt/'\n",
    "bert_model_file = 'pytorch_model.bin'\n",
    "\n",
    "d(bert_path)\n",
    "d(bert_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = transformers.BertTokenizer(vocab_file=f'{bert_path}vocab.txt')\n",
    "tokenized = data.corp.apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([101, 7108, 1135, 646, 11179, 212, 1189, 1120, 743, 23467, 16883, 13256, 205, 5442, 1015, 17464, 759, 3920, 112, 189, 3498, 6919, 16762, 769, 8354, 683, 812, 3245, 1122, 178, 4751, 752, 1020, 18163, 4661, 22084, 15808, 662, 1712, 813, 112, 189, 5782, 646, 27821, 816, 646, 1396, 3674, 1290, 178, 112, 182, 2623, 980, 102]),\n",
       "       list([101, 173, 112, 1123, 229, 728, 2697, 713, 3582, 5922, 178, 112, 182, 9321, 5342, 708, 5438, 1396, 28640, 17484, 15626, 223, 102])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.values[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ознакомимся с конфигурацией модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 28996}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open(f'{bert_path}bert_config.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конфигурация модели включает в себя ограничение на максимальную длину эмбеддинга (параметр *max_position_embeddings*).\n",
    "\n",
    "Найдём максимальную длину токена (соответствует длине эмбеддинга) в нашем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(tokenized, key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной работы модели необходимо оставить в датасете только те объекты, которые не превышают установленное ограничение.\n",
    "\n",
    "В целях экономии машинного времени ограничим максимальную длину эмбеддинга в ещё большей степени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of the items:\n",
      "original:   159571\n",
      "restricted: 114393\n",
      "fraction:   71.7%\n"
     ]
    }
   ],
   "source": [
    "max_position_embeddings = 80\n",
    "\n",
    "tokenized_short = tokenized.apply(position_embeddings_filter, max_pos=max_position_embeddings)\n",
    "tokenized_short.drop(index=tokenized_short[tokenized_short == 0].index, inplace=True)\n",
    "\n",
    "print('amount of the items:\\noriginal:   {}\\nrestricted: {}\\nfraction:   {:.1%}'\n",
    "      .format(tokenized.shape[0],\n",
    "              tokenized_short.shape[0],\n",
    "              tokenized_short.shape[0] / tokenized.shape[0])\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данному условию (ограничению по длине) удовлетворяет большая часть датасета, что хорошо с точки зрения репрезентативности:  большинство текстов - действительно не очень длинные.\n",
    "\n",
    "Однако, с точки зрения машинного времени (доступной вычислительной мощности) придётся ограничиться лишь небольшой частью вновь полученного набора данных.\n",
    "\n",
    "Сформируем выборку, сохранив баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_n_samples = 10000\n",
    "\n",
    "tokenized_short_sample_index = sample_func(data.loc[tokenized_short.index],\n",
    "                                           tokenized_n_samples,\n",
    "                                           'target',\n",
    "                                           frac_one=frac_class_1,\n",
    "                                           return_index=True)\n",
    "\n",
    "tokenized_short_sample = tokenized_short[tokenized_short_sample_index]\n",
    "\n",
    "tokenized_short_sample.reset_index(drop=True, inplace=True)\n",
    "tokenized_short_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем длину всех токенов одинаковой, равной длине самого длинного токена. Для этого удлиним массивы до необходимой длины. Добавленным элементам присвоим нулевые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60c0cfd875447448fd7f5291a51e8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 312 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "padded = []\n",
    "for i in notebook.tqdm(range(tokenized_short_sample.shape[0])):\n",
    "    padded.append(tokenized_short_sample.values[i] + [0]*(max_position_embeddings-len(tokenized_short_sample.values[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 77 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 80)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "padded = np.array(padded)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   776,  7640, 21805,   980,   178,   854,  5438,   688,\n",
       "          646,  3189,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       [  101,   788,  3075,  3510,   734,   788,  3075,  3510,   734,\n",
       "          738,  2145,  3520,   182,   203,   233, 15814,  5540,  3277,\n",
       "          646,  2067,  4206, 28201,   689,  9294,   662,  1238,  3739,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи маски *attention_mask* обозначим ненулевые позиции в *padded* единицами, а нулевые (незначащие) - нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 80)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем конфигурацию модели и саму модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = transformers.BertConfig.from_json_file(f'{bert_path}bert_config.json')\n",
    "bert_model = transformers.BertModel.from_pretrained(f'{bert_path}{bert_model_file}', config=bert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним векторизацию - сформируем эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc94f2da80f145f48d889bb5a5d04687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 21min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 200\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    padded_batch = torch.LongTensor(padded[(batch_size * i):(batch_size*(i+1))] )\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[(batch_size * i):(batch_size*(i+1))] )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings_batch = bert_model(input_ids=padded_batch, attention_mask=attention_mask_batch)\n",
    "    \n",
    "    embeddings.append(embeddings_batch[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим эмбеддинги в матрицу признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_features = np.concatenate(embeddings)\n",
    "bert_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49360603, -0.23898077,  0.4389935 , ...,  0.6176871 ,\n",
       "        -0.86993784,  0.13711601],\n",
       "       [ 0.8886719 , -0.20079303,  0.1106492 , ...,  0.46675897,\n",
       "        -0.6267636 , -0.28431734]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_features[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Адаптация массива эмбеддингов к применяемым функциям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректной работы используемых в работе функций необходимо поместить массив эмбеддингов вместе с массивом целевого признака в датафрейм.\n",
    "\n",
    "Убедимся, что длины массивов совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_features.shape[0] == data.target[tokenized_short_sample_index].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_759</th>\n",
       "      <th>emb_760</th>\n",
       "      <th>emb_761</th>\n",
       "      <th>emb_762</th>\n",
       "      <th>emb_763</th>\n",
       "      <th>emb_764</th>\n",
       "      <th>emb_765</th>\n",
       "      <th>emb_766</th>\n",
       "      <th>emb_767</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493606</td>\n",
       "      <td>-0.238981</td>\n",
       "      <td>0.438994</td>\n",
       "      <td>0.130449</td>\n",
       "      <td>-0.478443</td>\n",
       "      <td>0.161358</td>\n",
       "      <td>-0.200543</td>\n",
       "      <td>0.097896</td>\n",
       "      <td>0.710276</td>\n",
       "      <td>-0.234599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.744939</td>\n",
       "      <td>0.365976</td>\n",
       "      <td>0.059414</td>\n",
       "      <td>-0.111625</td>\n",
       "      <td>-0.125937</td>\n",
       "      <td>0.617687</td>\n",
       "      <td>-0.869938</td>\n",
       "      <td>0.137116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888672</td>\n",
       "      <td>-0.200793</td>\n",
       "      <td>0.110649</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>-0.390708</td>\n",
       "      <td>0.412642</td>\n",
       "      <td>-0.414981</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>0.302613</td>\n",
       "      <td>-0.231825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310539</td>\n",
       "      <td>0.429558</td>\n",
       "      <td>-0.017159</td>\n",
       "      <td>-0.316017</td>\n",
       "      <td>-0.394899</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>0.466759</td>\n",
       "      <td>-0.626764</td>\n",
       "      <td>-0.284317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.362144</td>\n",
       "      <td>0.079172</td>\n",
       "      <td>0.131711</td>\n",
       "      <td>0.040333</td>\n",
       "      <td>-0.674066</td>\n",
       "      <td>0.578170</td>\n",
       "      <td>0.437802</td>\n",
       "      <td>0.174256</td>\n",
       "      <td>0.246273</td>\n",
       "      <td>0.085462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393744</td>\n",
       "      <td>0.113762</td>\n",
       "      <td>0.127942</td>\n",
       "      <td>0.153627</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>-0.184254</td>\n",
       "      <td>0.365620</td>\n",
       "      <td>-0.005807</td>\n",
       "      <td>0.364162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.401402</td>\n",
       "      <td>-0.284934</td>\n",
       "      <td>-0.235779</td>\n",
       "      <td>-0.091475</td>\n",
       "      <td>-0.338438</td>\n",
       "      <td>0.213594</td>\n",
       "      <td>0.201409</td>\n",
       "      <td>-0.110042</td>\n",
       "      <td>0.350604</td>\n",
       "      <td>-0.260918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586635</td>\n",
       "      <td>0.344407</td>\n",
       "      <td>-0.213413</td>\n",
       "      <td>-0.123215</td>\n",
       "      <td>0.112594</td>\n",
       "      <td>-0.273448</td>\n",
       "      <td>0.261232</td>\n",
       "      <td>-0.189423</td>\n",
       "      <td>0.407664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.613844</td>\n",
       "      <td>-0.016272</td>\n",
       "      <td>0.348877</td>\n",
       "      <td>0.026169</td>\n",
       "      <td>-0.656297</td>\n",
       "      <td>0.383256</td>\n",
       "      <td>-0.117549</td>\n",
       "      <td>0.246334</td>\n",
       "      <td>0.531314</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621736</td>\n",
       "      <td>0.235166</td>\n",
       "      <td>-0.045918</td>\n",
       "      <td>0.249991</td>\n",
       "      <td>-0.340269</td>\n",
       "      <td>0.197663</td>\n",
       "      <td>0.338269</td>\n",
       "      <td>-0.749350</td>\n",
       "      <td>-0.273718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0  0.493606 -0.238981  0.438994  0.130449 -0.478443  0.161358 -0.200543   \n",
       "1  0.888672 -0.200793  0.110649  0.001981 -0.390708  0.412642 -0.414981   \n",
       "2  0.362144  0.079172  0.131711  0.040333 -0.674066  0.578170  0.437802   \n",
       "3  0.401402 -0.284934 -0.235779 -0.091475 -0.338438  0.213594  0.201409   \n",
       "4  0.613844 -0.016272  0.348877  0.026169 -0.656297  0.383256 -0.117549   \n",
       "\n",
       "      emb_7     emb_8     emb_9  ...   emb_759   emb_760   emb_761   emb_762  \\\n",
       "0  0.097896  0.710276 -0.234599  ...  0.402100  0.744939  0.365976  0.059414   \n",
       "1  0.017419  0.302613 -0.231825  ...  0.310539  0.429558 -0.017159 -0.316017   \n",
       "2  0.174256  0.246273  0.085462  ...  0.393744  0.113762  0.127942  0.153627   \n",
       "3 -0.110042  0.350604 -0.260918  ...  0.586635  0.344407 -0.213413 -0.123215   \n",
       "4  0.246334  0.531314  0.030343  ...  0.621736  0.235166 -0.045918  0.249991   \n",
       "\n",
       "    emb_763   emb_764   emb_765   emb_766   emb_767  target  \n",
       "0 -0.111625 -0.125937  0.617687 -0.869938  0.137116       0  \n",
       "1 -0.394899  0.065953  0.466759 -0.626764 -0.284317       1  \n",
       "2  0.025253 -0.184254  0.365620 -0.005807  0.364162       0  \n",
       "3  0.112594 -0.273448  0.261232 -0.189423  0.407664       1  \n",
       "4 -0.340269  0.197663  0.338269 -0.749350 -0.273718       0  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bert = pd.DataFrame(data=bert_features)\n",
    "\n",
    "columns_emb = {}\n",
    "for i in range(len(data_bert.columns)):\n",
    "    columns_emb[i] = f'emb_{i}'\n",
    "\n",
    "data_bert.rename(columns_emb, axis=1, inplace=True)\n",
    "data_bert_features = data_bert.columns\n",
    "\n",
    "data_bert = data_bert.join(data.target[tokenized_short_sample_index].reset_index(drop=True),\n",
    "                           on=data_bert.index,\n",
    "                           how='left',\n",
    "                          )\n",
    "data_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем обучающую, валидационную и тестовую выборки.\n",
    "\n",
    "Поскольку исходная выборка содержит весьма большое количество объектов (150k+), размеры валидационной и тестовой выборок можно взять несколько меньше, чем обычно (в пользу обучающей выборки): разделение выполним в пропорции 4:1:1.\n",
    "\n",
    "Признак и целевой признак:\n",
    "* признак - векторизированный корпус текстов;\n",
    "* целевой признак - столбец с классом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_valid | test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим исходную выборку на обучающую и тестовую. Разделять будем, формируя массивы с индексом. Затем уже по индексу будем брать из датафрейма непосредственно сами данные.\n",
    "\n",
    "При разделении сохраним баланс классов: при помощи функции *class_ratio_control* соотношение классов в исходной, обучающей и тестовой выборках будет различаться не более, чем на заданный процент. По умолчанию установлено 5%, т.е. соответствие - не сверхстрогое, а такое, какое может встретиться в реальных данных на практике. При этом исключены случайные сильные перекосы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of the classes:\n",
      "original: 0.1132\n",
      "train:    0.1137\n",
      "test:     0.1104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_index_train_valid, data_index_test = class_ratio_control(df=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(len(data_index_train_valid))\n",
    "d(len(data_index_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of the classes:\n",
      "original: 0.1131\n",
      "train:    0.1130\n",
      "test:     0.1136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_index_train_valid_bert, data_index_test_bert = class_ratio_control(df=data_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(len(data_index_train_valid_bert))\n",
    "d(len(data_index_test_bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv: train | valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидацию развернём вручную, так как необходимо учесть две особенности:\n",
    "* и на входе, и на выходе - массивы с индексами объектов, а не с непосредственно значениями; библиотечные функции больше ориентированы на работу с массивами значений, и вворачивать туда индексы - довольно громоздко;\n",
    "* при малой величине *cv* (малом числе проходов кросс-валидации) выборка должна разбиваться на тестовую и валидационную в соответствии с заданным размером последней.\n",
    "\n",
    "Второе условие необходимо для того, чтобы больше данных отводилось на обучающую выборку. К примеру, при *cv*=3 выборка обычно разбивается в пропорции *train*=67%, *valid*=33%. В нашем случае размер валидационной выборки указывается явно, и, таким образом, при малом *cv* и *valid_size* (точнее, при *cv * valid_size < 1.0*) не все данные побывают в валидационной выборке. Зато обучение при каждом проходе будет выполняться на большем объёме данных.\n",
    "\n",
    "Пример работы функции *cv_indexes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_0: [ 30  40  50  60  70  80  90 100] valid_0: [10 20]\n",
      "train_1: [ 10  20  50  60  70  80  90 100] valid_1: [30 40]\n",
      "train_2: [ 10  20  30  40  70  80  90 100] valid_2: [50 60]\n"
     ]
    }
   ],
   "source": [
    "# defaults: cv=3, valid_size=0.2\n",
    "\n",
    "tr, vl = cv_indexes(np.arange(10, 101, 10))\n",
    "\n",
    "for i in range(3):\n",
    "    print(f'train_{i}: {tr[i]} valid_{i}: {vl[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function transforms the dict with hyperparameters into the dataframe format\n",
    "\n",
    "def dict_to_df(params_dict={}):\n",
    "    return pd.DataFrame(data=itertools.product(*params_dict.values()), columns=params_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function transforms features into the necessary format\n",
    "\n",
    "def features_processing(data, algorithm, purpose, counter=None):\n",
    "    if algorithm == 'tf_idf':\n",
    "        if purpose == 'train':\n",
    "            return counter.fit_transform(data)\n",
    "        elif (purpose == 'valid') or (purpose == 'test'):\n",
    "            return counter.transform(data)\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    if algorithm == 'tf_idf_catboost':\n",
    "        if purpose == 'train':\n",
    "            return np.array(pd.DataFrame.sparse.from_spmatrix(counter.fit_transform(data)))\n",
    "        elif (purpose == 'valid') or (purpose == 'test'):\n",
    "            return np.array(pd.DataFrame.sparse.from_spmatrix(counter.transform(data)))\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    elif algorithm == 'bert':\n",
    "        if purpose == 'train':\n",
    "            return data\n",
    "        elif (purpose == 'valid') or (purpose == 'test'):\n",
    "            return data\n",
    "        else:\n",
    "            return data\n",
    "    \n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function computes the models using the hyperparameters grid, implements cross-validation,\n",
    "# returns the results of the best model: F1-score and the values of the hyperparameters\n",
    "\n",
    "def custom_grid_search_cv(model_init,\n",
    "                          df_params,\n",
    "                          features_col,\n",
    "                          features_algorithm,\n",
    "                          counter=None,\n",
    "                          df=data,\n",
    "                          index_train_valid=data_index_train_valid,\n",
    "                          cv=3,\n",
    "                          valid_size=0.2\n",
    "                         ):\n",
    "    \n",
    "    index_train, index_valid = cv_indexes(index_train_valid, cv=cv, valid_size=valid_size)\n",
    "    df_score = df_params.copy()\n",
    "    full_params_dict = []\n",
    "    \n",
    "    for i in notebook.tqdm(range(df_params.shape[0])):\n",
    "        model = None\n",
    "        try:\n",
    "            model = model_init.copy()\n",
    "        except:\n",
    "            model = model_init\n",
    "        \n",
    "        model.set_params(**df_params.loc[i].to_dict())\n",
    "\n",
    "        score = []\n",
    "        exception = False\n",
    "        for j in range(cv):\n",
    "            X_train = features_processing(data=df.loc[index_train[j], features_col],\n",
    "                                          algorithm=features_algorithm,\n",
    "                                          purpose='train',\n",
    "                                          counter=counter\n",
    "                                         )\n",
    "            X_valid = features_processing(data=df.loc[index_valid[j], features_col],\n",
    "                                          algorithm=features_algorithm,\n",
    "                                          purpose='valid',\n",
    "                                          counter=counter\n",
    "                                         )\n",
    "            y_train = df.loc[index_train[j], 'target']\n",
    "            y_valid = df.loc[index_valid[j], 'target']\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_valid)\n",
    "                score.append(f1_score(y_valid, y_pred))\n",
    "            except:\n",
    "                exception = True\n",
    "                break\n",
    "\n",
    "        if exception == False:\n",
    "            df_score.loc[i, 'score'] = np.mean(score)\n",
    "            print(df_score.loc[i].to_dict())\n",
    "        else:\n",
    "            df_score.loc[i, 'score'] = 0.0\n",
    "        \n",
    "        full_params_dict.append(model.get_params())\n",
    "        \n",
    "    best_score = df_score.loc[df_score.score.idxmax(), 'score']\n",
    "    best_params = df_score.loc[df_score.score.idxmax(), df_score.columns[:-1]].to_dict()\n",
    "    full_best_params = full_params_dict[df_score.score.idxmax()]\n",
    "\n",
    "    print('the best score:  {:.4f}\\nthe best parameters: {}'.format(best_score, best_params))\n",
    "\n",
    "    return best_score, best_params, full_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function tests the model on the test sample\n",
    "\n",
    "def testing(model,\n",
    "            params_dict,\n",
    "            features_col,\n",
    "            features_algorithm,\n",
    "            counter=None,\n",
    "            df=data,\n",
    "            index_train=data_index_train_valid,\n",
    "            index_test=data_index_test\n",
    "           ):\n",
    "    \n",
    "    X_train = features_processing(data=df.loc[index_train, features_col],\n",
    "                                  algorithm=features_algorithm,\n",
    "                                  purpose='train',\n",
    "                                  counter=counter\n",
    "                                 )\n",
    "    X_test  = features_processing(data=df.loc[index_test, features_col],\n",
    "                                  algorithm=features_algorithm,\n",
    "                                  purpose='test',\n",
    "                                  counter=counter\n",
    "                                 )\n",
    "    y_train = df.loc[index_train, 'target']\n",
    "    y_test  = df.loc[index_test, 'target']\n",
    "    \n",
    "    model.set_params(**params_dict)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "\n",
    "    print('testing score:  {:.4f}'.format(score))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и валидация (*TF-IDF*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=r_state,\n",
    "                                  class_weight='balanced'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров.\n",
    "\n",
    "В процессе исследования были опробованы значения, различающиеся на порядки. Также были опробованы различные значения *n_estimators* (от 20 до 200). В финальной (текущей) версии - диапазоны, включающие в себя \"экстремумы\": оптимальные значения не являются границами диапазонов, а находятся внутри них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': array([1024, 1448, 2048]),\n",
       " 'min_samples_split': array([256, 362, 512])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rf = {\n",
    "    'max_depth': np.geomspace(2**10, 2**11, 3, dtype='int'),\n",
    "    'min_samples_split': np.geomspace(2**8, 2**9, 3, dtype='int')\n",
    "}\n",
    "\n",
    "params_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e11bc62f4344bdf90fa0c0cc61ba7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 1024.0, 'min_samples_split': 256.0, 'score': 0.711525863087545}\n",
      "{'max_depth': 1024.0, 'min_samples_split': 362.0, 'score': 0.7119640997804071}\n",
      "{'max_depth': 1024.0, 'min_samples_split': 512.0, 'score': 0.7099752570428914}\n",
      "{'max_depth': 1448.0, 'min_samples_split': 256.0, 'score': 0.7105043683969968}\n",
      "{'max_depth': 1448.0, 'min_samples_split': 362.0, 'score': 0.7117722327744791}\n",
      "{'max_depth': 1448.0, 'min_samples_split': 512.0, 'score': 0.7128411056487923}\n",
      "{'max_depth': 2048.0, 'min_samples_split': 256.0, 'score': 0.7098645882873761}\n",
      "{'max_depth': 2048.0, 'min_samples_split': 362.0, 'score': 0.7104902489569543}\n",
      "{'max_depth': 2048.0, 'min_samples_split': 512.0, 'score': 0.712756914180244}\n",
      "\n",
      "the best score:  0.7128\n",
      "the best parameters: {'max_depth': 1448.0, 'min_samples_split': 512.0}\n",
      "Wall time: 14min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_rf, \\\n",
    "best_params_rf, \\\n",
    "full_best_params_rf \\\n",
    "= custom_grid_search_cv(model_init=model_rf,\n",
    "                        df_params=dict_to_df(params_rf),\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf',\n",
    "                        counter=count_tf_idf\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(n_jobs=-1,\n",
    "                              random_state=r_state,\n",
    "                              class_weight='balanced',\n",
    "                              multi_class='ovr'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров.\n",
    "\n",
    "Алгоритм оптимизации *saga* использовать не будем: он даёт весьма средние результаты, но при этом в некоторых случаях приводит к зависанию ядра (или - если это не зависание - выполняет расчёт неприемлемо медленно). Несовместимые значения будут автоматически пропущены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'], 'penalty': ['l1', 'l2']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_lr = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "params_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c885ac796029485bb870a4bdd1a5a92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'newton-cg', 'penalty': 'l2', 'score': 0.7426195440135599}\n",
      "{'solver': 'lbfgs', 'penalty': 'l2', 'score': 0.742579885582794}\n",
      "{'solver': 'liblinear', 'penalty': 'l1', 'score': 0.7434814589730013}\n",
      "{'solver': 'liblinear', 'penalty': 'l2', 'score': 0.7425503583176756}\n",
      "{'solver': 'sag', 'penalty': 'l2', 'score': 0.7426195440135599}\n",
      "\n",
      "the best score:  0.7435\n",
      "the best parameters: {'solver': 'liblinear', 'penalty': 'l1'}\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_lr, \\\n",
    "best_params_lr, \\\n",
    "full_best_params_lr \\\n",
    "= custom_grid_search_cv(model_init=model_lr,\n",
    "                        df_params=dict_to_df(params_lr),\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf',\n",
    "                        counter=count_tf_idf\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание процесса подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь пошагово описан процесс подбора гиперпараметров. Привести **непосредственно** сами расчёты (промежуточные) не представляется возможным ввиду огромных затрат машинного времени на каждый перезапуск тетрадки. Приведён только **окончательный** вариант. Развёрнутые **результаты** расчёта приведены в Приложении в конце работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 1**. В процессе исследования были опробованы различные комбинации значений в весьма широких пределах (см. ниже) - расчёт длился на протяжении 10-12 часов. Это - не считая пробных предварительных расчётов для определения порядка значений в первом приближении. Анализ полученных результатов выявил, каким образом влияет на метрику каждый из гиперпараметров, и это позволило исключить из сетки заведомо неоптимальные значения. Тем самым время обучения было сокращено до приемлемого.\n",
    "\n",
    "* n_estimators: 100,\n",
    "* num_iterations: 400,\n",
    "* learning_rate: 0.05\n",
    "* num_leaves: (32,  45,  63,  90), //*90 - не завершён*\n",
    "* min_data_in_leaf: (2, 3, 7),\n",
    "* max_depth: (16, 22, 31, 45, 63)\n",
    "\n",
    "**Шаг 2**. Глубина дерева *max_depth* в алгоритме *Light GBM* не настолько влияет на результат, как, например, в *Random Forest*. Чтобы сократить машинное время, не будем перебирать этот параметр, а присвоим ему фиксированное значение. Оптимальным представляется *max_depth*=32.\n",
    "\n",
    "Минимальное количество строк в листе *min_data_in_leaf* - в данном случае чем меньше, тем лучше. Поэтому будем рассматривать два значения: *min_data_in_leaf*=\\[2, 4\\].\n",
    "\n",
    "Число листьев *num_leaves* - чем больше, тем лучше. Но увеличение может привести к переобучению модели. Поэтому рассмотрим только три значения из опробованных ранее: *num_leaves*=\\[32, 45, 63\\].\n",
    "\n",
    "Также попробуем загрубить бустинг: число итераций уменьшим вдвое (200 вместо 400), но при этом увеличим шаг (0.10 вместо 0.05).\n",
    "\n",
    "* n_estimators: 100,\n",
    "* num_iterations: 200,\n",
    "* learning_rate: 0.10\n",
    "* num_leaves: (32,  45,  63)\n",
    "* min_data_in_leaf: (2, 4),\n",
    "* max_depth: 32\n",
    "\n",
    "**Шаг 3**. Результат получился, хоть и незначительно, но хуже. Это означает, что следует попробовать пойти по пути увеличения числа итераций и уменьшения шага спуска.\n",
    "\n",
    "Так как при этом кратно увеличится время расчёта, придётся отказаться от перебора тех параметров, что мы подбирали ранее. Примем такие фиксированные их значения, которые давали лучшие результаты.\n",
    "\n",
    "Примем *min_data_in_leaf*=2; *num_leaves*=64. Будем иметь в виду, что в случае низких результатов на тестовой выборке надо попробовать уменьшить *num_leaves* (попробовать значения 32, 45), так как причиной может быть переобучение.\n",
    "\n",
    "* n_estimators: 150,\n",
    "* num_iterations: 500,\n",
    "* learning_rate: 0.05\n",
    "* num_leaves: 64\n",
    "* min_data_in_leaf: 2,\n",
    "* max_depth: 32\n",
    "\n",
    "**Шаг 4**. Результат получился немного лучше, но расчёт длится слишком долго. Хотелось бы относительно безболезненно сократить машинное время. Можно попробовать уменьшить число итераций кросс-валидации (2 вместо 3) - на столь большой выборке качество может практически не снизиться. Также попробуем уменьшить количество корзин *max_bin* (64 вместо 255). Уменьшение *max_bin* в общем случае снижает точность, что - плохо, но при этом - уменьшает эффект переобучения, что - хорошо.\n",
    "\n",
    "Результат шага 4 оказался удовлетворительным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb = lgb.LGBMClassifier(n_estimators=150,\n",
    "                              n_jobs=-1,\n",
    "                              random_state=r_state,\n",
    "                              class_weight='balanced',\n",
    "                              objective='binary',\n",
    "                              metric='binary_logloss',\n",
    "                              num_iterations=500,\n",
    "                              learning_rate=0.05,\n",
    "                              boosting='gbdt',\n",
    "                              max_depth=32,\n",
    "                              max_bin=64,\n",
    "                              num_leaves=64,\n",
    "                              min_data_in_leaf=2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f43da5fd56a4b5c989688e436c356f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7729056585818308}\n",
      "\n",
      "the best score:  0.7729\n",
      "the best parameters: {}\n",
      "Wall time: 11min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_gb, \\\n",
    "best_params_gb, \\\n",
    "full_best_params_gb \\\n",
    "= custom_grid_search_cv(model_init=model_gb,\n",
    "                        df_params=dict_to_df(),\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf',\n",
    "                        counter=count_tf_idf,\n",
    "                        cv=2\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование уменьшенного датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CatBoost* не работает с разреженными матрицами (sparse matrix). Можно привести массив признаков к обычной матрице, но тогда его объём составит 97.6 Гб, что не приемлемо с точки зрения доступного аппаратного обеспечения.\n",
    "\n",
    "Чтобы опробовать работу алгоритма *CatBoost*, сформируем уменьшенный датасет из исходного. Элементы выберем случайным образом.\n",
    "\n",
    "Сформируем уменьшенный датасет и массивы индексов к нему. При этом сохраним баланс классов, как в исходном датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples_cb = 12000\n",
    "\n",
    "data_cb = sample_func(data, n_samples_cb, 'target', frac_one=frac_class_1)\n",
    "data_cb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of the classes:\n",
      "original: 0.1132\n",
      "train:    0.1141\n",
      "test:     0.1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_index_train_valid_cb, data_index_test_cb = class_ratio_control(df=data_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание процесса подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание процесса подбора - аналогично *LightGBM*.\n",
    "\n",
    "**Шаг 1**. В качестве бэйслайна установлены значения, аналогичные подобранным в *LightGBM* (так как эти алгоритмы похожи между собой). Результат получился удовлетворительным, но всё равно требовал дальнейшего улучшения: в зависимости от состава обучающей выборки (формирование обучающей и тестовой выборок не закреплено параметром *random_state* - этого, в свою очередь, требует алгоритм разбиения на train/test) результат на тестовой выборке получался то выше, то ниже, чем требование ТЗ (*F1-score* > 0.75).\n",
    "\n",
    "Необходимо отметить, что влияние состава выборки на результат оказалось даже сильнее, чем изменение значений гиперпараметров (тех, что перебирались по сетке). Причина: тексты сильно различаются между собой по длине и по составу слов, а из-за малого размера выборки такие различия не \"усредняются\" и сказываются намного заметнее, чем на исходной большой выборке. Такое влияние - непредсказуемое, и влияет на метрику весьма существенно.\n",
    "\n",
    "* loss_function: 'Logloss',\n",
    "* iterations: 500,\n",
    "* learning_rate: 0.05,\n",
    "* grow_policy: 'Depthwise',\n",
    "* min_data_in_leaf: 2,\n",
    "* auto_class_weights: 'Balanced',\n",
    "* thread_count: -1,\n",
    "* logging_level: 'Silent'\n",
    "* depth: (4, 7, 16),\n",
    "* border_count: (61, 125, 254)\n",
    "\n",
    "**Шаг 2**. Расчёт длится достаточно долго. Попробуем загрубить спуск, а глубину *depth* - переберём немного более дробно.\n",
    "\n",
    "* loss_function: 'Logloss',\n",
    "* iterations: 200,\n",
    "* learning_rate: 0.10,\n",
    "* grow_policy: 'Depthwise',\n",
    "* min_data_in_leaf: 2,\n",
    "* auto_class_weights: 'Balanced',\n",
    "* thread_count: -1,\n",
    "* logging_level: 'Silent'\n",
    "* depth: (4, 6, 10, 16),\n",
    "* border_count: (61, 125, 254)\n",
    "\n",
    "**Шаг 3**. Загрубление спуска не оказало негативного влияния на обучение: моделям, чтобы завершить обучение, хватает как количества шагов, так и их дискретности. Время обучения хотелось бы сократить ещё, и такая возможность есть: необходимо сократить сетку гиперпараметров. В отличие от *LightGBM*, от неё не получится отказаться совсем: из-за малого размера датасета результаты слишком нестабильны - не понятно, какие значения окажутся в итоге лучше. Но в этом и нет необходимости: опять же, из-за размера датасета небольшой перебор всё-таки можно себе позволить с точки зрения затрат машинного времени. Уберём малые значения *depth*: с ними результат оказывается в среднем хуже. Уберём и самое малое значение *border_count*: иногда именно при нём получается самый лучший результат, но чаще - всё-таки при больших значениях.\n",
    "\n",
    "* loss_function: 'Logloss',\n",
    "* iterations: 200,\n",
    "* learning_rate: 0.10,\n",
    "* grow_policy: 'Depthwise',\n",
    "* min_data_in_leaf: 2,\n",
    "* auto_class_weights: 'Balanced',\n",
    "* thread_count: -1,\n",
    "* logging_level: 'Silent'\n",
    "* depth: (10, 16),\n",
    "* border_count: (125, 254)\n",
    "\n",
    "Результат шага 3 оказался условно\\* удовлетворительным. Окончательный вариант расчёта приведён ниже.\n",
    "\n",
    "(\\*) - результат на тестовой выборке варьируется в относительно широких пределах; бывает как лучше, так и хуже, чем на валидационной выборке; иногда удовлетворяет требованиям ТЗ, но чаще - нет. К сожалению, отсутствует возможность обучить и проверить модель на полном датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель.\n",
    "\n",
    "Установим значения, аналогичные установленным в *LightGBM*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb = cb.CatBoostClassifier(loss_function='Logloss',\n",
    "                                 iterations=200,\n",
    "                                 learning_rate=0.10,\n",
    "                                 grow_policy='Depthwise',\n",
    "                                 min_data_in_leaf=2,\n",
    "                                 auto_class_weights='Balanced',\n",
    "                                 thread_count=-1,\n",
    "                                 logging_level='Silent'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': [10, 16], 'border_count': array([125, 254])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_cb = {\n",
    "    'depth': [10, 16],\n",
    "    'border_count': np.geomspace(2**7, 2**8, 2, dtype='int') - 2\n",
    "}\n",
    "\n",
    "params_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e429a5d2db54367bd02f1469e7c6b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 10.0, 'border_count': 125.0, 'score': 0.6981474665685192}\n",
      "{'depth': 10.0, 'border_count': 254.0, 'score': 0.7057823129251701}\n",
      "{'depth': 16.0, 'border_count': 125.0, 'score': 0.709229176620481}\n",
      "{'depth': 16.0, 'border_count': 254.0, 'score': 0.724822437937192}\n",
      "\n",
      "the best score:  0.7248\n",
      "the best parameters: {'depth': 16.0, 'border_count': 254.0}\n",
      "Wall time: 14min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_cb, \\\n",
    "best_params_cb, \\\n",
    "full_best_params_cb \\\n",
    "= custom_grid_search_cv(model_init=model_cb,\n",
    "                        df_params=dict_to_df(params_cb),\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf_catboost',\n",
    "                        counter=count_tf_idf,\n",
    "                        cv=2,\n",
    "                        df=data_cb,\n",
    "                        index_train_valid=data_index_train_valid_cb\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование (*TF-IDF*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним тестирование моделей, показавших лучшие результаты на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.7130\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_rf = testing(model=RandomForestClassifier(),\n",
    "                        params_dict=full_best_params_rf,\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf',\n",
    "                        counter=count_tf_idf\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.7386\n",
      "Wall time: 8.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_lr = testing(model=LogisticRegression(),\n",
    "                        params_dict=full_best_params_lr,\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf',\n",
    "                        counter=count_tf_idf\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.7667\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_gb = testing(model=lgb.LGBMClassifier(),\n",
    "                        params_dict=full_best_params_gb,\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf',\n",
    "                        counter=count_tf_idf\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.7348\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_cb = testing(model=cb.CatBoostClassifier(),\n",
    "                        params_dict=full_best_params_cb,\n",
    "                        features_col='corp_lemm',\n",
    "                        features_algorithm='tf_idf_catboost',\n",
    "                        counter=count_tf_idf,\n",
    "                        df=data_cb,\n",
    "                        index_train=data_index_train_valid_cb,\n",
    "                        index_test=data_index_test_cb\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и валидация (*BERT*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм и логика действий в целом - такие же, как и в разделе выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_bert = RandomForestClassifier(n_estimators=700,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=r_state,\n",
    "                                       class_weight='balanced',\n",
    "                                       max_depth=8\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': array([ 32,  50,  80, 127])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_rf_bert = {\n",
    "    'min_samples_split': np.geomspace(2**5, 2**7, 4, dtype='int')\n",
    "}\n",
    "\n",
    "params_rf_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb6e114559c4b199c2cf83449b104db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 32.0, 'score': 0.6368787731016833}\n",
      "{'min_samples_split': 50.0, 'score': 0.6441596909030362}\n",
      "{'min_samples_split': 80.0, 'score': 0.6356582806105338}\n",
      "{'min_samples_split': 127.0, 'score': 0.6246159899514218}\n",
      "\n",
      "the best score:  0.6442\n",
      "the best parameters: {'min_samples_split': 50.0}\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_rf_bert, \\\n",
    "best_params_rf_bert, \\\n",
    "full_best_params_rf_bert \\\n",
    "= custom_grid_search_cv(model_init=model_rf_bert,\n",
    "                        df_params=dict_to_df(params_rf_bert),\n",
    "                        features_col=data_bert_features,\n",
    "                        features_algorithm='bert',\n",
    "                        df=data_bert,\n",
    "                        index_train_valid=data_index_train_valid_bert\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_bert = LogisticRegression(n_jobs=-1,\n",
    "                                   random_state=r_state,\n",
    "                                   class_weight='balanced',\n",
    "                                   multi_class='ovr'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'], 'penalty': ['l1', 'l2']}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_lr_bert = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "params_lr_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a85f2f80846a7b4cb806c74595a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'newton-cg', 'penalty': 'l2', 'score': 0.6737860303564983}\n",
      "{'solver': 'lbfgs', 'penalty': 'l2', 'score': 0.6698397740752227}\n",
      "{'solver': 'liblinear', 'penalty': 'l1', 'score': 0.6692406697883831}\n",
      "{'solver': 'liblinear', 'penalty': 'l2', 'score': 0.6737134317079843}\n",
      "{'solver': 'sag', 'penalty': 'l2', 'score': 0.6578106116520362}\n",
      "\n",
      "the best score:  0.6738\n",
      "the best parameters: {'solver': 'newton-cg', 'penalty': 'l2'}\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_lr_bert, \\\n",
    "best_params_lr_bert, \\\n",
    "full_best_params_lr_bert \\\n",
    "= custom_grid_search_cv(model_init=model_lr_bert,\n",
    "                        df_params=dict_to_df(params_lr_bert),\n",
    "                        features_col=data_bert_features,\n",
    "                        features_algorithm='bert',\n",
    "                        df=data_bert,\n",
    "                        index_train_valid=data_index_train_valid_bert\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb_bert = lgb.LGBMClassifier(n_estimators=150,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=r_state,\n",
    "                                   class_weight='balanced',\n",
    "                                   objective='binary',\n",
    "                                   metric='binary_logloss',\n",
    "                                   num_iterations=500,\n",
    "                                   learning_rate=0.05,\n",
    "                                   boosting='gbdt',\n",
    "                                   max_depth=16,\n",
    "                                   num_leaves=64,\n",
    "                                   min_data_in_leaf=2\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_bin': array([ 32,  63, 127])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_gb_bert = {\n",
    "    'max_bin': np.geomspace(2**5, 2**7, 3, dtype='int')\n",
    "}\n",
    "\n",
    "params_gb_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c18fd3431b643fc8bf00eb6e026413b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_bin': 32.0, 'score': 0.6306230341966139}\n",
      "{'max_bin': 63.0, 'score': 0.6339362157534246}\n",
      "{'max_bin': 127.0, 'score': 0.6250374812593704}\n",
      "\n",
      "the best score:  0.6339\n",
      "the best parameters: {'max_bin': 63.0}\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_gb_bert, \\\n",
    "best_params_gb_bert, \\\n",
    "full_best_params_gb_bert \\\n",
    "= custom_grid_search_cv(model_init=model_gb_bert,\n",
    "                        df_params=dict_to_df(params_gb_bert),\n",
    "                        features_col=data_bert_features,\n",
    "                        features_algorithm='bert',\n",
    "                        df=data_bert,\n",
    "                        index_train_valid=data_index_train_valid_bert,\n",
    "                        cv=2\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb_bert = cb.CatBoostClassifier(loss_function='Logloss',\n",
    "                                      iterations=200,\n",
    "                                      learning_rate=0.05,\n",
    "                                      grow_policy='Depthwise',\n",
    "                                      min_data_in_leaf=2,\n",
    "                                      auto_class_weights='Balanced',\n",
    "                                      thread_count=-1,\n",
    "                                      logging_level='Silent'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь - сетку гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': array([4, 5, 7]), 'border_count': array([ 5, 14, 30])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_cb_bert = {\n",
    "    'depth': np.geomspace(2**2, 2**3, 3, dtype='int'),\n",
    "    'border_count': np.geomspace(2**3, 2**5, 3, dtype='int') - 2\n",
    "}\n",
    "\n",
    "params_cb_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31502189d95479eadf60e37eb26b23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 4.0, 'border_count': 5.0, 'score': 0.6224557044079515}\n",
      "{'depth': 4.0, 'border_count': 14.0, 'score': 0.6353321242348674}\n",
      "{'depth': 4.0, 'border_count': 30.0, 'score': 0.6343151958725778}\n",
      "{'depth': 5.0, 'border_count': 5.0, 'score': 0.64508547008547}\n",
      "{'depth': 5.0, 'border_count': 14.0, 'score': 0.6587094096142502}\n",
      "{'depth': 5.0, 'border_count': 30.0, 'score': 0.6638226281319473}\n",
      "{'depth': 7.0, 'border_count': 5.0, 'score': 0.6539835828102365}\n",
      "{'depth': 7.0, 'border_count': 14.0, 'score': 0.6591567908602609}\n",
      "{'depth': 7.0, 'border_count': 30.0, 'score': 0.6559738479384161}\n",
      "\n",
      "the best score:  0.6638\n",
      "the best parameters: {'depth': 5.0, 'border_count': 30.0}\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_score_cb_bert, \\\n",
    "best_params_cb_bert, \\\n",
    "full_best_params_cb_bert \\\n",
    "= custom_grid_search_cv(model_init=model_cb_bert,\n",
    "                        df_params=dict_to_df(params_cb_bert),\n",
    "                        features_col=data_bert_features,\n",
    "                        features_algorithm='bert',\n",
    "                        df=data_bert,\n",
    "                        index_train_valid=data_index_train_valid_bert,\n",
    "                        cv=2\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование (*BERT*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним тестирование моделей, показавших лучшие результаты на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.6189\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_rf_bert = testing(model=RandomForestClassifier(),\n",
    "                             params_dict=full_best_params_rf_bert,\n",
    "                             features_col=data_bert_features,\n",
    "                             features_algorithm='bert',\n",
    "                             df=data_bert,\n",
    "                             index_train=data_index_train_valid_bert,\n",
    "                             index_test=data_index_test_bert\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.6683\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_lr_bert = testing(model=LogisticRegression(),\n",
    "                             params_dict=full_best_params_lr_bert,\n",
    "                             features_col=data_bert_features,\n",
    "                             features_algorithm='bert',\n",
    "                             df=data_bert,\n",
    "                             index_train=data_index_train_valid_bert,\n",
    "                             index_test=data_index_test_bert\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.5824\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_gb_bert = testing(model=lgb.LGBMClassifier(),\n",
    "                             params_dict=full_best_params_gb_bert,\n",
    "                             features_col=data_bert_features,\n",
    "                             features_algorithm='bert',\n",
    "                             df=data_bert,\n",
    "                             index_train=data_index_train_valid_bert,\n",
    "                             index_test=data_index_test_bert\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing score:  0.6361\n",
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_score_cb_bert = testing(model=cb.CatBoostClassifier(),\n",
    "                             params_dict=full_best_params_cb_bert,\n",
    "                             features_col=data_bert_features,\n",
    "                             features_algorithm='bert',\n",
    "                             df=data_bert,\n",
    "                             index_train=data_index_train_valid_bert,\n",
    "                             index_test=data_index_test_bert\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты (значения метрик *F1-score*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведём результаты расчёта (значения метрик *F1-score*) в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Light GBM</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th>stage</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TF-IDF</th>\n",
       "      <th>validation</th>\n",
       "      <td>0.712841</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.772906</td>\n",
       "      <td>0.724822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.712970</td>\n",
       "      <td>0.738624</td>\n",
       "      <td>0.766678</td>\n",
       "      <td>0.734807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">BERT</th>\n",
       "      <th>validation</th>\n",
       "      <td>0.644160</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>0.633936</td>\n",
       "      <td>0.663823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.618893</td>\n",
       "      <td>0.668269</td>\n",
       "      <td>0.582375</td>\n",
       "      <td>0.636119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Random Forest  Logistic Regression  Light GBM  CatBoost\n",
       "algorithm stage                                                              \n",
       "TF-IDF    validation       0.712841             0.743481   0.772906  0.724822\n",
       "          test             0.712970             0.738624   0.766678  0.734807\n",
       "BERT      validation       0.644160             0.673786   0.633936  0.663823\n",
       "          test             0.618893             0.668269   0.582375  0.636119"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data = [[best_score_rf, best_score_lr, best_score_gb, best_score_cb],\n",
    "                               [test_score_rf, test_score_lr, test_score_gb, test_score_cb],\n",
    "                               [best_score_rf_bert, best_score_lr_bert, best_score_gb_bert, best_score_cb_bert],\n",
    "                               [test_score_rf_bert, test_score_lr_bert, test_score_gb_bert, test_score_cb_bert]\n",
    "                              ],\n",
    "                       index = pd.MultiIndex.from_arrays([['TF-IDF', 'TF-IDF', 'BERT', 'BERT'],\n",
    "                                                          ['validation', 'test', 'validation', 'test']],\n",
    "                                                         names=('algorithm', 'stage')\n",
    "                                                        ),\n",
    "                       columns = ['Random Forest', 'Logistic Regression', 'Light GBM', 'CatBoost']\n",
    "                      )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этапе подготовки выполнено ознакомление с данными. Выявлен значительный **дисбаланс** классов (1:9). Пропусков нет.\n",
    "\n",
    "Конечная **цель** подготовки признаков - преобразование текстов в **векторы**: машина понимает только числа. Было рассмотрено два предназначенных для этого алгоритма: ***TF-IDF*** и ***BERT***. Строго говоря, *TF-IDF* - это название не самого алгоритма, а функций, положенных в его основу, но для краткости приемлемо называть его так.\n",
    "\n",
    "Сформировано **два варианта** корпуса текстов - для каждого из алгоритмов (т.к. есть различия в требованиях к подготовке). Из **обоих** корпусов удалены небуквенные символы, лишние пробелы. Обработка корпуса для ***BERT*** на этом была **завершена** - всё остальное сделает **предобученная** модель. На корпусе для ***TF-IDF*** также **выполнены** удаление стоп-слов, токенизация и лемматизация средствами библиотеки *nltk* (***WordNetLemmatizer***).\n",
    "\n",
    "В силу **повышенной ресурсоёмкости** процессов, выполняемых моделью *BERT*, корпус текстов для работы с ней пришлось **уменьшить**. После выполнения токенизации **удалены** объекты длиной **более 80 токенов** (осталось 72% объектов), а затем из оставшихся **отобрано** случайным образом **10000** объектов. При этом соотношение классов целевого признака **сохранено** таким же, как в исходном датасете.\n",
    "\n",
    "Выполнено **разделение** данных (полного датасета, датасета для *BERT*) на тренировочную и тестовую выборки в соотношении 1:6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение, валидация, тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения применялись следующие **алгоритмы**:\n",
    "\n",
    "* *Random Forest*;\n",
    "* *Logistic Regression*;\n",
    "* *Light GBM*;\n",
    "* *CatBoost*.\n",
    "\n",
    "**Кросс-валидация** выполнялась в три (*Random Forest*, *Logistic Regression*) либо в два (*Light GBM*, *CatBoost*) прохода. **Особенность** применённого алгоритма кросс-валидации заключается в том, что, возможно, **не все** данные обучающей выборки побывают в валидационной. Устанавливается размер валидационной выборки (доля от размера всей обучающей выборки) и число проходов. Так, если размер равен 0.2, а число проходов - 3, то в валидационной выборке побывает только 60% данных обучающей выборки. Это сделано для **максимизации** объёма данных, на которых модель непосредственно **обучается**.\n",
    "\n",
    "**Гиперпараметры** подбирались поэтапно: вначале \"нащупывался\" рабочий диапазон (приведено только описание, результаты - в Приложении), а затем - тонкая настройка (приведён расчёт). Характер рассматриваемого датасета таков, что **процесс обучения** на нём занимает весьма **значительное время** в контексте сроков завершения исследования и доступной вычислительной мощности. Это - ограничения. Поэтому вполне возможно, что достигнутые значения метрик - не предел. Вместе с тем, следует отметить, что оптимизация **признавалась завершённой** только в тот момент, когда дальнейшее изменение гиперпараметров уже **не давало** заметного эффекта. Запас по оптимизации, возможно, не исчерпан в области подготовки признаков: процесс - творческий, и там есть, с чем поэкспериментировать.\n",
    "\n",
    "**Лучшая модель**, полученная в данном исследовании, создана алгоритмом ***Light GBM*** и обучена на **полном** наборе данных, преобразованных в векторы алгоритмом ***TF-IDF*** (*TfidfVectorizer* библиотеки *Scikit-learn*).  \n",
    "Кроме того, эта модель - единственная, **стабильно удовлетворяющая** требованиям ТЗ (*F1-score* > 0.75) как на тестовых данных (*F1-score* = **0.76...0.78**), так и на обучающих (*F1-score* = 0.75...0.77).\n",
    "\n",
    "**На втором месте** - модель, созданная алгоритмом ***Logistic Regression***, обученная на **полном** наборе данных (***TF-IDF***). Её качество - пограничное с требованиями ТЗ: в зависимости от состава выборок (см. ниже - о *random_state*) иногда **удаётся** уложиться в требования ТЗ на тестовой выборке, но это - **нестабильный** результат.\n",
    "\n",
    "**Остальные** модели **не удовлетворяют** требованиям ТЗ.\n",
    "\n",
    "Компромисс, связанный с **ограничениями по ресурсам**, отразился на результатах. Ожидалось, что более \"умное\" преобразование в векторы нейронной сетью ***BERT*** позволит достичь наилучших результатов. Но этого не произошло из-за **отсутствия возможности** обучать модели на полном наборе данных: пришлось обойтись лишь небольшой выборкой (**около 6%** от исходной). В итоге результаты получились значительно **ниже**, чем у моделей, обученных на полном наборе данных и подготовленных более \"простым\" способом (*TF-IDF*).\n",
    "\n",
    "**Схожая проблема** возникла с алгоритмом ***CatBoost*** на данных, преобразованных ***TF-IDF*** (пришлось работать с небольшой выборкой). Но первоначальная причина проблемы - в другом: *CatBoost* **не работает** с **разреженными** матрицами, а обычная матрица, полученная из разреженной, **превышает** имеющийся объём ОЗУ на 1-2 порядка. Впрочем, алгоритм работает весьма медленно, и даже на маленькой выборке требуется время, сопоставимое с временем работы других алгоритмов на полном наборе данных. Возможно, это связано с тем, что подаваемая на вход матрица - не разреженная.\n",
    "\n",
    "Стоит обратить внимание, что модели, обученные на **полном** наборе данных (*Random Forest*, *Logistic Regression*, *Light GBM*, данные преобразованы *TF-IDF*), на **тестовой** выборке показывают результат, как правило, **близкий и немного лучший**, чем на валидационной выборке. Это говорит о следующем:\n",
    "\n",
    "* модели обучены очень хорошо: нет ни недообучения, ни переобучения;\n",
    "* объём данных - достаточно большой, чтобы тестовая выборка статистически не отличалась от валидационной;\n",
    "* улучшение результата на тестовой выборке наблюдается потому, что на фоне первых двух факторов модель во время теста обучается на большей по размеру выборке (тренировочная плюс валидационная).\n",
    "\n",
    "**О *random_state***. Параметр *random_state* **не зафиксирован** при разбиении на тренировочную и тестовую выборки в целях обеспечения возможности **автоматического подбора** такого разбиения, при котором с заданной точностью **сохраняется соотношение** классов целевого признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственная модель, которая строго и стабильно удовлетворяет требованиям ТЗ, - модель ***Light GBM***, для обучения которой использовался **полный** набор данных, преобразованных алгоритмом ***TF-IDF*** (*F1-score* = 0.76...0.78).\n",
    "\n",
    "Также представляет интерес модель ***Logistic Regression***, обученная на **том же** наборе данных. Отставание от необходимого уровня точности у этой модели - **минимальное** (\\~0.01), но зато она обладает другим преимуществом - **высокой скоростью** обучения. На тестовых данных модель *Logistic Regression* обучилась и сделала предсказание за 18 секунд против 7 минут у модели *Light GBM*. Это - более чем **в 20 раз быстрее**.\n",
    "\n",
    "Модель ***Light GBM*** **рекомендуется** к внедрению.\n",
    "\n",
    "Модель ***Logistic Regression*** с некоторыми оговорками **может быть интересна** для внедрения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты подбора гиперпараметров для *LightGBM*  и *CatBoost* (*TF-IDF*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *LightGBM*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  \n",
    "n_estimators=100  \n",
    "n_jobs=-1,  \n",
    "random_state=r_state,  \n",
    "class_weight='balanced',  \n",
    "objective='binary',  \n",
    "metric='binary_logloss',  \n",
    "num_iterations=400  \n",
    "learning_rate=0.05  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 2.0, 'max_depth': 16.0, 'score': 0.7504880760034182}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 2.0, 'max_depth': 22.0, 'score': 0.7518492081820263}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 2.0, 'max_depth': 31.0, 'score': 0.7489382456019079}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 2.0, 'max_depth': 45.0, 'score': 0.7489382456019079}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 2.0, 'max_depth': 63.0, 'score': 0.7489382456019079}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 3.0, 'max_depth': 16.0, 'score': 0.7516566670198676}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 3.0, 'max_depth': 22.0, 'score': 0.7526529573831803}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 3.0, 'max_depth': 31.0, 'score': 0.7495301335789781}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 3.0, 'max_depth': 45.0, 'score': 0.7495301335789781}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 3.0, 'max_depth': 63.0, 'score': 0.7495301335789781}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 7.0, 'max_depth': 16.0, 'score': 0.752216860511667}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 7.0, 'max_depth': 22.0, 'score': 0.7508869753359529}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 7.0, 'max_depth': 31.0, 'score': 0.7499040284966618}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 7.0, 'max_depth': 45.0, 'score': 0.7499040284966618}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 7.0, 'max_depth': 63.0, 'score': 0.7499040284966618}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 2.0, 'max_depth': 16.0, 'score': 0.756357074789499}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 2.0, 'max_depth': 22.0, 'score': 0.7584757921973456}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 2.0, 'max_depth': 31.0, 'score': 0.759322815369111}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 2.0, 'max_depth': 45.0, 'score': 0.7550220449605046}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 2.0, 'max_depth': 63.0, 'score': 0.7550220449605046}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 3.0, 'max_depth': 16.0, 'score': 0.75624596877734}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 3.0, 'max_depth': 22.0, 'score': 0.759452539937531}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 3.0, 'max_depth': 31.0, 'score': 0.759581589916143}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 3.0, 'max_depth': 45.0, 'score': 0.753279594360448}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 3.0, 'max_depth': 63.0, 'score': 0.753279594360448}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 7.0, 'max_depth': 16.0, 'score': 0.7558170264053962}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 7.0, 'max_depth': 22.0, 'score': 0.7587351236045762}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 7.0, 'max_depth': 31.0, 'score': 0.7595214720070634}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 7.0, 'max_depth': 45.0, 'score': 0.7525010188021835}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 7.0, 'max_depth': 63.0, 'score': 0.7525010188021835}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 2.0, 'max_depth': 16.0, 'score': 0.7564967249892063}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 2.0, 'max_depth': 22.0, 'score': 0.7632724852260777}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 2.0, 'max_depth': 31.0, 'score': 0.7668477283752214}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 2.0, 'max_depth': 45.0, 'score': 0.766192487161526}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 2.0, 'max_depth': 63.0, 'score': 0.7604046241929917}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 3.0, 'max_depth': 16.0, 'score': 0.7590297726278221}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 3.0, 'max_depth': 22.0, 'score': 0.7643657905737826}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 3.0, 'max_depth': 31.0, 'score': 0.7663278921709152}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 3.0, 'max_depth': 45.0, 'score': 0.7647802560862802}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 3.0, 'max_depth': 63.0, 'score': 0.7597102497545686}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 7.0, 'max_depth': 16.0, 'score': 0.7579527214615925}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 7.0, 'max_depth': 22.0, 'score': 0.7621188884702516}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 7.0, 'max_depth': 31.0, 'score': 0.766407953406953}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 7.0, 'max_depth': 45.0, 'score': 0.762561166387289}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 7.0, 'max_depth': 63.0, 'score': 0.7594317113110272}  \n",
    "{'num_leaves': 90.0, 'min_data_in_leaf': 2.0, 'max_depth': 16.0, 'score': 0.7593724028469931}  \n",
    "{'num_leaves': 90.0, 'min_data_in_leaf': 2.0, 'max_depth': 22.0, 'score': 0.7654219544659256}  \n",
    "  \n",
    "2)  \n",
    "n_estimators=100  \n",
    "n_jobs=-1,  \n",
    "random_state=r_state,  \n",
    "class_weight='balanced',  \n",
    "objective='binary',  \n",
    "metric='binary_logloss',  \n",
    "num_iterations=200  \n",
    "learning_rate=0.10  \n",
    "max_depth=32  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 2.0, 'score': 0.7478428229679043}  \n",
    "{'num_leaves': 32.0, 'min_data_in_leaf': 4.0, 'score': 0.7490562773369622}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 2.0, 'score': 0.7586257706315541}  \n",
    "{'num_leaves': 45.0, 'min_data_in_leaf': 4.0, 'score': 0.7571181793489211}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 2.0, 'score': 0.7660735237681212}  \n",
    "{'num_leaves': 63.0, 'min_data_in_leaf': 4.0, 'score': 0.7643192600524543}  \n",
    "  \n",
    "3)  \n",
    "n_estimators=150  \n",
    "n_jobs=-1,  \n",
    "random_state=r_state,  \n",
    "class_weight='balanced',  \n",
    "objective='binary',  \n",
    "metric='binary_logloss',  \n",
    "num_iterations=500  \n",
    "learning_rate=0.05  \n",
    "max_depth=32  \n",
    "num_leaves=64.0  \n",
    "min_data_in_leaf=2.0  \n",
    "{'score': 0.7722166540770777}  \n",
    "  \n",
    "4)  \n",
    "n_estimators=150,  \n",
    "n_jobs=-1,  \n",
    "random_state=r_state,  \n",
    "class_weight='balanced',  \n",
    "objective='binary',  \n",
    "metric='binary_logloss',  \n",
    "num_iterations=500,  \n",
    "learning_rate=0.05,  \n",
    "boosting='gbdt',  \n",
    "max_depth=32,  \n",
    "max_bin=64,  \n",
    "num_leaves=64,  \n",
    "min_data_in_leaf=2  \n",
    "{'score': 0.7746759038267277}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *CatBoost*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  \n",
    "loss_function='Logloss',  \n",
    "iterations=500,  \n",
    "learning_rate=0.05,  \n",
    "grow_policy='Depthwise',  \n",
    "min_data_in_leaf=2,  \n",
    "auto_class_weights='Balanced',  \n",
    "thread_count=-1,  \n",
    "logging_level='Silent'  \n",
    "{'depth': array(\\[ 4,  7, 16\\]), 'border_count': array(\\[ 61, 125, 254\\])}  \n",
    "{'depth': 4.0, 'border_count': 61.0, 'score': 0.6722395458543216}  \n",
    "{'depth': 4.0, 'border_count': 125.0, 'score': 0.6708153885710613}  \n",
    "{'depth': 4.0, 'border_count': 254.0, 'score': 0.6734939183595492}  \n",
    "{'depth': 7.0, 'border_count': 61.0, 'score': 0.686461691048847}  \n",
    "{'depth': 7.0, 'border_count': 125.0, 'score': 0.6839250574636615}  \n",
    "{'depth': 7.0, 'border_count': 254.0, 'score': 0.6792443454278922}  \n",
    "{'depth': 16.0, 'border_count': 61.0, 'score': 0.6873772407448846}  \n",
    "{'depth': 16.0, 'border_count': 125.0, 'score': 0.6821022727272728}  \n",
    "{'depth': 16.0, 'border_count': 254.0, 'score': 0.6892485346863791}  \n",
    "  \n",
    "2)  \n",
    "loss_function='Logloss',  \n",
    "iterations=200,  \n",
    "learning_rate=0.10,  \n",
    "grow_policy='Depthwise',  \n",
    "min_data_in_leaf=2,  \n",
    "auto_class_weights='Balanced',  \n",
    "thread_count=-1,  \n",
    "logging_level='Silent'  \n",
    "{'depth': array(\\[ 4,  6, 10, 16\\]), 'border_count': array(\\[ 61, 125, 254\\])}  \n",
    "{'depth': 4.0, 'border_count': 61.0, 'score': 0.6740169317192816}  \n",
    "{'depth': 4.0, 'border_count': 125.0, 'score': 0.6841518027725557}  \n",
    "{'depth': 4.0, 'border_count': 254.0, 'score': 0.6732768760291696}  \n",
    "{'depth': 6.0, 'border_count': 61.0, 'score': 0.687623300182667}  \n",
    "{'depth': 6.0, 'border_count': 125.0, 'score': 0.6787083350006002}  \n",
    "{'depth': 6.0, 'border_count': 254.0, 'score': 0.6701201589198618}  \n",
    "{'depth': 10.0, 'border_count': 61.0, 'score': 0.6836491298797285}  \n",
    "{'depth': 10.0, 'border_count': 125.0, 'score': 0.6803100285771251}  \n",
    "{'depth': 10.0, 'border_count': 254.0, 'score': 0.6824751580849142}  \n",
    "{'depth': 16.0, 'border_count': 61.0, 'score': 0.7037387519141103}  \n",
    "{'depth': 16.0, 'border_count': 125.0, 'score': 0.6932359589636585}  \n",
    "{'depth': 16.0, 'border_count': 254.0, 'score': 0.692525114634744}  \n",
    "  \n",
    "3)  \n",
    "loss_function='Logloss',  \n",
    "iterations=200,  \n",
    "learning_rate=0.10,  \n",
    "grow_policy='Depthwise',  \n",
    "min_data_in_leaf=2,  \n",
    "auto_class_weights='Balanced',  \n",
    "thread_count=-1,  \n",
    "logging_level='Silent'  \n",
    "{'depth': \\[10, 16\\], 'border_count': array(\\[125, 254\\])}  \n",
    "{'depth': 10.0, 'border_count': 125.0, 'score': 0.7164429923635482}  \n",
    "{'depth': 10.0, 'border_count': 254.0, 'score': 0.7152183454026773}  \n",
    "{'depth': 16.0, 'border_count': 125.0, 'score': 0.7026980482204364}  \n",
    "{'depth': 16.0, 'border_count': 254.0, 'score': 0.7103819176427157}  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
