{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из банка стали уходить клиенты. Необходимо спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.\n",
    "\n",
    "Столбец *Exited* отражает факт ухода клиента.\n",
    "\n",
    "### Метрики\n",
    "\n",
    "* *F1*-score > 0,59;\n",
    "* *ROC-AUC*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "# Scikit-learn libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,\\\n",
    "                            roc_curve,\\\n",
    "                            accuracy_score,\\\n",
    "                            confusion_matrix,\\\n",
    "                            recall_score,\\\n",
    "                            precision_score,\\\n",
    "                            f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем некоторые общие настройки среды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "r_state = 123  # Здесь же зафиксируем значение random_state - сквозное по всему проекту"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ознакомление с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем файл и просмотрим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл открылся нормально, данные распознались корректно. Имеются пропуски в одном столбце - *Tenure*.\n",
    "\n",
    "Столбцы *RowNumber*, *CustomerId* и *Surname* не нужны: достаточно индекса таблицы.\n",
    "\n",
    "Удалим *RowNumber*, *CustomerId* и *Surname*, но перед этим сразу выполним проверку на наличие дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переименуем столбцы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products</th>\n",
       "      <th>card</th>\n",
       "      <th>active</th>\n",
       "      <th>salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score country  gender  age  tenure    balance  products  card  active  \\\n",
       "0    619  France  Female   42     2.0       0.00         1     1       1   \n",
       "1    608   Spain  Female   41     1.0   83807.86         1     0       1   \n",
       "2    502  France  Female   42     8.0  159660.80         3     1       0   \n",
       "3    699  France  Female   39     1.0       0.00         2     0       0   \n",
       "4    850   Spain  Female   43     2.0  125510.82         1     1       1   \n",
       "\n",
       "      salary  exited  \n",
       "0  101348.88       1  \n",
       "1  112542.58       0  \n",
       "2  113931.57       1  \n",
       "3   93826.63       0  \n",
       "4   79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df.rename(columns={'creditscore': 'score',\n",
    "                   'geography': 'country',\n",
    "                   'numofproducts': 'products',\n",
    "                   'hascrcard': 'card',\n",
    "                   'isactivemember': 'active',\n",
    "                   'estimatedsalary': 'salary'},\n",
    "          inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь данные готовы к предобработке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean       650.528800\n",
       "std         96.653299\n",
       "min        350.000000\n",
       "25%        584.000000\n",
       "50%        652.000000\n",
       "75%        718.000000\n",
       "max        850.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *country*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *gender*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *age*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean        38.921800\n",
       "std         10.487806\n",
       "min         18.000000\n",
       "25%         32.000000\n",
       "50%         37.000000\n",
       "75%         44.000000\n",
       "max         92.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *balance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10000.000000\n",
       "mean      76485.889288\n",
       "std       62397.405202\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%       97198.540000\n",
       "75%      127644.240000\n",
       "max      250898.090000\n",
       "Name: balance, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.balance.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения столбцов *score*, *country*, *gender*, *age*, *balance* - корректные, аномалий нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *salary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10000.000000\n",
       "mean     100090.239881\n",
       "std       57510.492818\n",
       "min          11.580000\n",
       "25%       51002.110000\n",
       "50%      100193.915000\n",
       "75%      149388.247500\n",
       "max      199992.480000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe = df.salary.describe()\n",
    "describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимум аномально мал. Рассмотрим подробнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAD7CAYAAACyhDqIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAUT0lEQVR4nO3df2xddf0/8Oc67PggLKV1kG4YiYuQxv2BrJHEBIxFsolD/jBmywIaDJqYuMTwGYq4tDpGRtk+hGBG0H/8a2GJQYcbC0NDTPzHhGVOXUgADeCPNcDaTbcvbnO95/uHH/qB0Xbt2nfv7b2Px38973Pveb/OOe9znz3n3HMXVFVVBQCAWddW7w4AADQrQQsAoBBBCwCgEEELAKAQQQsAoBBBCwCgEEELAKCQi+rdgckcO/b/UquVe8xXV9elGR4+Wez9G1kr1560dv2tXHvS2vW3cu1Ja9ev9rK1t7UtyOWXf3DctoYOWrVaVTRovbOMVtXKtSetXX8r1560dv2tXHvS2vWrvT5cOgQAKETQAgAoRNACAChE0AIAKETQAgAoRNACAChE0AIAKKShn6MFMNvO/Hs0S5Zcdt75Tp0+mxP//Ncc9AhoZoIW0FLaP7Awt/330+edb8//3J4Tc9AfoLm5dAgAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIxztAC7ts8X/l4kXnPwx4phTAhRG0oIVdvOgiz5QCKMilQwCAQpzRAhrWVC9tJi5vAo1J0AIa1lQvbSYubwKNSdACgBbhLPHcE7QAoEU001niqYbGM/8enYPeTEzQAgDmnel8a7qefOsQAKCQlj6jdebfo1my5LLzztdM16nffap1stqbqWYAqJeWDlrtH1jYcg9r9IBKoNH4hQKaWUsHLYBW0Ohnsv0DSDMTtKAQ/6XTKASZ5jeV481UbpVh9gla8L9mOxhN9cPtqYfWTPkAKJQB45kv38BrRYIW/K96/dc/1XsFSywbgLIELQDmhVb8pjjzn6AFMA9N56dUmkUrflOc+e+8o/TYsWP59re/nb/85S9pb2/PRz7ykWzevDmdnZ05dOhQ+vv7c/r06Sxbtizbtm1LV1dXkkzaBvPZVP+rbkVT/fA/fWY0i9oXzkGPmtd0f0oFqI/zHhEXLFiQu+++OzfccEOSZHBwMNu3b8+WLVty7733ZuvWrent7c3jjz+e7du3Z+vWranVahO2wXw3nf+qW8107nOzDsfXimeqoJmddzR3dHSMhawkue666/Lkk0/m8OHDWbRoUXp7e5Mk69aty80335ytW7dO2gZzbaIPLmelmMxs3w80nQDVLCFUaIRp3qNVq9Xy5JNPpq+vL0NDQ1m6dOlYW2dnZ2q1Wo4fPz5pW0dHx+z1vsFM56DiZs2504pfez7fvjjdkNmKl0tn+36gVtwPm6lmz8XjQk0raD3wwAO55JJLcscdd+SXv/xlqT6N6eq6tPgypmqqHzLTuWfi4gb/4Gq1D9b5Yjb3xal+wM2Xy6X12mebaaw0Sy0T1TGT+qY6Bhr92D4dzb4/zIUpB63BwcG8/vrreeKJJ9LW1pbu7u4cOXJkrH1kZCRtbW3p6OiYtG06hodPplarpvWa6ZjOin/rrfP/zzrdDTmV95xts13zfNAsB4p3lNgXm0W91k0zbZPZHPf1rHm8OpYsueyC62v0Y2eJdX3m36Np/8D5v7RSr7N4jbRN2toWTHhyaEpB65FHHsnhw4fz4x//OO3t7UmSFStW5NSpUzlw4EB6e3uza9eurF69+rxtADQmz6lqPPW8z83jNGbHebfeK6+8kh/96Ee5+uqrs27duiTJVVddlR07duThhx/OwMDAex7hkCRtbW0TtvEfzXJAK3HfgnshoD58sDaeZrrPrVWd99PsYx/7WF566aVx266//vrs2bNn2m00zwGtxM/WlPiNQACoB9+7Zd6aLzdoA5zLoy9ah63c4JrlEiMA/6cVLwm26i9HCFoNrlkuMQLQ2lr1lyMELQCmpRUfYAsXStACYFrcHzkxIZRzCVqMy8ECpsZYaTyTbZNzp8/2/a1CKOcStBjXbB8sfBjRrHywNp6pbpPE/a2UJ2gxJ6Z74AOAZtBW7w4AADQrZ7SmYD5c9poPfWTmbGeg0TguTU7QmoL5cA/GfOgjM2c7A43GcWlyLh0CABQiaAEAFCJoAQAUImgBABQiaAEAFCJoAQAUImgBABQiaAEAFOKBpUBT8HRqLoT9htIELaApeDo1F8J+Q2kuHQIAFCJoAQAUImgBABQiaAEAFCJoAQAUImgBABQiaAEAFCJoAQAUImgBABQiaAEAFCJoAQAUImgBABQiaAEAFCJoAQAUImgBABRy0VRmGhwczP79+/P3v/89e/bsyTXXXJMk6evrS3t7exYtWpQk2bhxY2688cYkyaFDh9Lf35/Tp09n2bJl2bZtW7q6ugqVAQDQeKZ0Ruvmm2/Ozp07s2zZsve1PfbYY3n66afz9NNPj4WsWq2We++9N/39/dm/f396e3uzffv22e05AECDm1LQ6u3tTXd395Tf9PDhw1m0aFF6e3uTJOvWrcuzzz57YT0EAJinpnTpcDIbN25MVVVZuXJl7rnnnixevDhDQ0NZunTp2DydnZ2p1Wo5fvx4Ojo6pvzeXV2XzrR7AECLW7Lksrote0ZBa+fOnenu7s6ZM2fy4IMPZvPmzbN6iXB4+GRqtWrW3u9c9VzxAMDceOutE0Xfv61twYQnh2b0rcN3Lie2t7dn/fr1OXjw4Nj0I0eOjM03MjKStra2aZ3NAgCY7y44aL399ts5ceI/CbGqquzbty89PT1JkhUrVuTUqVM5cOBAkmTXrl1ZvXr1LHQXAGD+mNKlwy1btuS5557L0aNHc9ddd6WjoyNPPPFENmzYkNHR0dRqtSxfvjwDAwNJkra2tjz88MMZGBh4z+MdAABayZSC1qZNm7Jp06b3Td+9e/eEr7n++uuzZ8+eC+8ZAMA858nwAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIUIWgAAhQhaAACFCFoAAIWcN2gNDg6mr68v1157bV5++eWx6a+++mrWrl2bVatWZe3atXnttdem1AYA0CrOG7Ruvvnm7Ny5M8uWLXvP9IGBgaxfvz779+/P+vXr09/fP6U2AIBWcd6g1dvbm+7u7vdMGx4ezosvvpg1a9YkSdasWZMXX3wxIyMjk7YBALSSiy7kRUNDQ7nyyiuzcOHCJMnChQtzxRVXZGhoKFVVTdjW2dk5ez0HAGhwFxS05kpX16X17gIAMM8tWXJZ3ZZ9QUGru7s7b7zxRkZHR7Nw4cKMjo7mzTffTHd3d6qqmrBtuoaHT6ZWqy6ki1NSzxUPAMyNt946UfT929oWTHhy6IIe79DV1ZWenp7s3bs3SbJ379709PSks7Nz0jYAgFZy3jNaW7ZsyXPPPZejR4/mrrvuSkdHR5555pl8//vfz3333ZfHH388ixcvzuDg4NhrJmsDAGgV5w1amzZtyqZNm943ffny5fnpT3867msmawMAaBWeDA8AUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFCIoAUAUIigBQBQiKAFAFDIRTN9g76+vrS3t2fRokVJko0bN+bGG2/MoUOH0t/fn9OnT2fZsmXZtm1burq6ZtxhAID5YsZBK0kee+yxXHPNNWN/12q13Hvvvdm6dWt6e3vz+OOPZ/v27dm6detsLA4AYF4ocunw8OHDWbRoUXp7e5Mk69aty7PPPltiUQAADWtWzmht3LgxVVVl5cqVueeeezI0NJSlS5eOtXd2dqZWq+X48ePp6OiYjUUCADS8GQetnTt3pru7O2fOnMmDDz6YzZs355ZbbpmNvqWr69JZeR8AoHUtWXJZ3ZY946DV3d2dJGlvb8/69evzjW98I1/+8pdz5MiRsXlGRkbS1tY27bNZw8MnU6tVM+3ihOq54gGAufHWWyeKvn9b24IJTw7N6B6tt99+OydO/KfzVVVl37596enpyYoVK3Lq1KkcOHAgSbJr166sXr16JosCAJh3ZnRGa3h4OBs2bMjo6GhqtVqWL1+egYGBtLW15eGHH87AwMB7Hu8AANBKZhS0PvzhD2f37t3jtl1//fXZs2fPTN4eAGBe82R4AIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQooGrVdffTVr167NqlWrsnbt2rz22mslFwcA0FCKBq2BgYGsX78++/fvz/r169Pf319ycQAADeWiUm88PDycF198MT/5yU+SJGvWrMkDDzyQkZGRdHZ2Tuk92toWlOremCsu/6+6zFfPZTf6fPVcdqPPV89lN/p89Vx2o89Xz2U3+nz1XHajz1fPZc/2fKXzxGTvv6CqqqrEQg8fPpzvfOc7eeaZZ8am3Xrrrdm2bVs+/vGPl1gkAEBDcTM8AEAhxYJWd3d33njjjYyOjiZJRkdH8+abb6a7u7vUIgEAGkqxoNXV1ZWenp7s3bs3SbJ379709PRM+f4sAID5rtg9Wkny5z//Offdd1/++c9/ZvHixRkcHMxHP/rRUosDAGgoRYMWAEArczM8AEAhghYAQCGCFgBAIYIWAEAhLRm0muHHro8dO5avfe1rWbVqVW677bZ885vfzMjISJLk2muvzW233Zbbb789t99+e1566aWx1z3//PNZvXp1brnllnzrW9/Kv/71rxm31UNfX19Wr149VuNvfvObJMmhQ4fyhS98IatWrcpXv/rVDA8Pj72mRFs9/O1vfxur+/bbb09fX18++clPJpl4vSTzt/7BwcH09fXl2muvzcsvvzw2fbJxPNdtpYxX+2RjP2mu8T/Rtp/r/bweY2C82icb+0nzjP/J9vG53r6zUn/Vgu68885q9+7dVVVV1e7du6s777yzzj2avmPHjlW//e1vx/5+6KGHqu9+97tVVVXVNddcU508efJ9rzl58mT1qU99qnr11Verqqqq+++/v/rhD384o7Z6+cxnPlO99NJL75k2Ojpaffazn61eeOGFqqqqaseOHdV9991XrK1RbNmypfrBD35QVdX466Wq5nf9L7zwQnXkyJH31TbZOJ7rtlLGq32ysV9VzTX+J9r2c7mf12sMTFT7u7177FdV84z/ifbxud6+s1V/ywWto0ePVitXrqzOnj1bVVVVnT17tlq5cmU1PDxc557NzLPPPlt95Stfqapq4gPtvn37qq9//etjf//hD3+obr311hm11ct4B5Tf//731ec///mxv4eHh6vrrruuWFsjOH36dHXDDTdUhw8frqpq4gNtM9T/7tomG8dz3TbXtZ/r3WO/qppz/E81aDXjMWCiWs8d+5PNO19rf8c7+/hcb9/Zqv+iCzirN68NDQ3lyiuvzMKFC5MkCxcuzBVXXJGhoaF5+9T6Wq2WJ598Mn19fWPT7rzzzoyOjuamm27Khg0b0t7enqGhoSxdunRsnqVLl2ZoaChJLritnjZu3JiqqrJy5crcc8897+tnZ2dnarVajh8/XqSto6NjbgqdxPPPP58rr7zyPT/Ufu56Wbx4cdPVP9k4rqpqTtvqedwYb+wnrTn+S+3njToGxhv7SfON/3fv43O9fWer/pa8R6vZPPDAA7nkkktyxx13JEl+/etf52c/+1l27tyZP/3pT9mxY0edezj7du7cmV/84hd56qmnUlVVNm/eXO8u1cVTTz2VL37xi2N/Wy+t5dyxnxj/reLcsZ8053oZbx+fb1ouaDXbj10PDg7m9ddfz6OPPpq2tv9szndqufTSS/OlL30pBw8eHJt+5MiRsdceOXJkbN4LbauXd5bf3t6e9evX5+DBg+/r58jISNra2tLR0VGkrd7eeOONvPDCC7ntttvGpo23Xt6Z3kz1TzaO57qtXsYb+0nrjv93prfCMWC8sZ803/g/dx+f6+07W/W3XNBqph+7fuSRR3L48OHs2LEj7e3tSZJ//OMfOXXqVJLk7Nmz2b9/f3p6epIkN954Y/74xz+OfVtq165d+dznPjejtnp4++23c+LEiSRJVVXZt29fenp6smLFipw6dSoHDhwY6+fq1auTpEhbvf385z/Ppz/96Vx++eVJJl4vSfPVP9k4nuu2ehhv7CetPf6TMvt5I46Bc8d+0nzjf7x9fK6372zV35K/ddgMP3b9yiuvZM2aNbn66qtz8cUXJ0muuuqq3H333env78+CBQty9uzZfOITn8j999+fD37wg0mSX/3qV9m2bVtqtVp6enry0EMP5ZJLLplR21z761//mg0bNmR0dDS1Wi3Lly/Ppk2bcsUVV+TgwYMZGBjI6dOns2zZsmzbti0f+tCHkqRIWz2tWrUq3/ve93LTTTclmXy9JPO3/i1btuS5557L0aNHc/nll6ejoyPPPPPMpON4rtvmsvZHH3103LG/Y8eO/O53v2uq8T9e/U888cSc7+f1GAMT7ffJ+8d+0lzjf6LPtx07dsz59p2N+lsyaAEAzIWWu3QIADBXBC0AgEIELQCAQgQtAIBCBC0AgEIELQCAQgQtAIBCBC0AgEL+P69kh7s1WNa0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df.salary, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function builds a plot of the salary by index\n",
    "\n",
    "def salary_plot(limit):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    df_plot = df.salary[df.salary < limit].sort_values()\n",
    "    df_plot.reset_index(drop=True, inplace=True)\n",
    "    plt.plot(df_plot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "salary_plot(describe['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAADECAYAAACcJVgjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXTT54Hu8a8kY4PxIlve5B3b2DiYLTghIZAUEgJJCXSamyZlQtpJZ3KnuZPTuT3pDG2n0EPS0zpkembaoTent+d2TmYy4TRdkpZSIBttlkIMmMUYbDA2eJE3eZF3W9Lv/pHGnSzYxpItWXo+/9mvLL968sYPv91kGIaBiIiIhBxzoCcgIiIi00MlLyIiEqJU8iIiIiFKJS8iIhKiVPIiIiIhSiUvIiISoiICPYHp0NXVj9frnysDbbYYnM4+v7xXuFKGvlOG/qEcfacMfefPDM1mEwkJ8685HpIl7/Uafiv5D95PfKMMfacM/UM5+k4Z+m6mMtTuehERkRClkhcREQlRKnkREZEQpZIXERGZIUMj7hn9fZM68W79+vVERkYSFRUFwJNPPsnatWs5deoUO3fuZHh4mIyMDPbs2YPNZgOYljEREZHZZnDYzfHqNk5fcnL6Ugf/8y+WULowaUZ+96S35H/wgx/wyiuv8Morr7B27Vq8Xi9f+9rX2LlzJ4cOHaK0tJRnn30WYFrGREREZguvYVBR085PD5znKz94m58euECdw8WapXZuW5YxY/OY8u76yspKoqKiKC0tBeChhx7i4MGD0zYmIiIS7IZG3Lx+opFv/t9j/PCXZ/njuRZuLEziG9tX8uzjq/nCpkXEzY+csflM+jr5J598EsMwWLlyJV/96ldxOBykp6ePjScmJuL1eunu7p6WMavVOukPZbPFTPq1k5GcHOvX9wtHytB3ytA/lKPvlOGfufpHuHClk+b2Pipq2rl4tYvegVFy0mL5359fwZplGUTOsXzs52Yqw0mV/AsvvIDdbmdkZITvfOc77N69mw0bNkz33KbM6ezz240GkpNjaW/v9ct7hStl6Dtl6B/K0XfKEPoGRzlZ086pix2cvezE86e+SbbOZWmejbXL0lmYGY/JZKKne+BjP+/PDM1m07gbtpMqebvdDkBkZCTbtm3jy1/+Mo888gjNzc1jr+ns7MRsNmO1WrHb7X4fExERCaSO7kGOnW/ld0evMjDsJn5+JHeVZrJiYTLpSfOZPzcCk8kU6Gl+yIQlPzAwgMfjITY2FsMwOHDgAMXFxZSUlDA0NMTx48cpLS1l3759bNq0CWBaxkRERGaaYRi0dQ1yqLyBIxVNACxekMj9d+SRkxobdKX+UROWvNPp5IknnsDj8eD1esnPz2fXrl2YzWaeeeYZdu3a9aHL3YBpGRMREZkJPf0j1DlcvFfVyoWrXXT3jWACPrUig003Z5GSEB3oKU6ayTCMkHvSgI7JBxdl6Dtl6B/K0XehmmHf4CjlF9o4/N5VWrsGAYiOimBJvo289DhWFCSRZJ3nl98VdMfkRUREQs3gsJsDR69QcbGD5o5+APLS43hoRQY5abHkpsURFfnxM+NnE5W8iIiEDbfHy4nqds7VdXKypp2BYTdFWVbuvyOPRdkJ5KXHBf1x9uuhkhcRkZA2POLhjZONVFzq4FJjDwBRkRaW5tm4bYmdpfmhe+t0lbyIiIQc18AI75x18MfKVhzOfjxeg+zUGDaUZlGYFc+KhcmYzaGzxX4tKnkREQkJbo+X1s4BXj3eyNtnHHgNg4yk+Wxalc3i3EQW5SQEeoozTiUvIiKzWn2Li6PnWim/0EZX7zBmk4nSRcncsSyd4tzEQE8voFTyIiIy6xiGwWWHi/88VMOV1l4sZhM35Caydc0CFmbGY7fND/QUg4JKXkREZo3hUQ8Hj13lcPlVBoc9RFjM3FWayX2rc4mNnrmnu80WKnkREQlqQyNu/ljZwnvn26htduH2eFmcm8CNhcncsjiNeVGqsmtRMiIiEpQGh90cPdfCr96qo29wlNTEaNatyGBpgY3FYX6sfbJU8iIiEjSutvZyvLqN8/Vd1Dl68RoGBZnx3Lc6lyV5oXs9+3RRyYuISMCdqXXy6vEGztV1YjaZWGCP5d5bsynOTqAoOyEsrmmfDip5EREJiMFhN++db+VEdTuVdZ0kxEZx18pMtqxZQMy8OYGeXkhQyYuIyIwaGBqlpqGHl45cwuEcICl+Lltuy2Xz6lwiLOZATy+kqORFRGTatXcPUn6hjfeqWmlo68MAIiPMfG5dARtvzgqph8IEE5W8iIhMi1G3l1OXOnjnrIMztU4AMpNj2LJmAYuyreSlxzEnYnY/yjXYqeRFRMSvnD1DVFxs55d/uMzQiAdrTCR335TFHcvTdSe6GaaSFxGRKTMMg6b2fmoau+noGeJys4uahm4A7LZoPnt7Hkvzk5gToWPtgaCSFxGR69Y/NMpbpx0cqWiirXsQgAiLmWTrXO6/I4/lC5NJt0XrWHuAqeRFRGRS6ltc/MerNdRc7aLFOYDHa1CYZeWeW7IpWWAjIS4Ks0o9qKjkRURkXBcbuznwxyucqXUyb24ECzPiWZpn4+biVHLSYgM9PRnHdR0k+bd/+zeKioqoqakB4NSpU2zZsoWNGzfy6KOP4nQ6x147HWMiIjIzBobc1Le4+M07dTzzXxXUtfSy4aYsfvz1u/jKA8t4YF2BCn4WmHTJnzt3jlOnTpGRkQGA1+vla1/7Gjt37uTQoUOUlpby7LPPTtuYiIhML8MwOFffyZ4XK/jKD95i978f51dv1ZFrj2X3l27moTsXEh8TFehpynWYVMmPjIywe/duvv3tb499r7KykqioKEpLSwF46KGHOHjw4LSNiYjI9DlR3cbufz/OP+87RX2Liw2lWfyvv1jCM397K9/cXkqcntU+K03qmPy//uu/smXLFjIzM8e+53A4SE9PH/s6MTERr9dLd3f3tIxZrdZJfyibLWbSr52M5GTtkvKVMvSdMvQP5fhh5+s6ef53VVTWOkmMi+KvNt/APasXjPuMdmXou5nKcMKSr6iooLKykieffHIm5uMXTmcfXq/hl/dKTo6lvb3XL+8VrpSh75ShfyjHP+sbHOXtMw5eevMScfMj+czaBWy6OZvIORb6XIP0XePnlKHv/Jmh2Wwad8N2wpIvLy+ntraWO++8E4CWlha+9KUvsX37dpqbm8de19nZidlsxmq1Yrfb/T4mIiJT5/Z4efuMg6r6Tpo6+nE4BwBITYzmW4+UEj1XF1uFogn/qz722GM89thjY1+vX7+e5557joKCAn72s59x/PhxSktL2bdvH5s2bQKgpKSEoaEhv46JiMj1a+0c4I2TTRyvbqOrdxhb3Fwyk+ezuiSN/PR4CjLj9eS3EDblf7qZzWaeeeYZdu3axfDwMBkZGezZs2faxkREZHKGRzz87tgVyi+0jW2xL85N4Iv3LKJkQaLuQhdGTIZh+OfgdRDRMfngogx9pwz9I9Rz7O4b5vUTjRypaKJ/yI3dFs2aJXZWFiWTkhDtl98R6hnOhKA6Ji8iIsGtoa2Pw+9d5WhVK16vwY2FyWy4KYuCzHjdZjbMqeRFRGaZgSE3Zy53cLbWSU1DN07XMFFzLHxqRQYbSjP9ttUus59KXkRkFjAMg/qWXo5VtfLWmWYGhz3EzY+kMMvKplVWblmcyvy5cwI9TQkyKnkRkSDV0z9CncNFvcPF6UtOrrT2YjLBouwEtq5ZoN3xMiGVvIhIEOkbHOWt0828WdFER88QACYTZKXE8PDdhawsTNb942XSVPIiIgHkNQwuNnRT2+zi9KUOLjb2ALDAHsv6GzPJS48jOzWGuZH6cy3XT6tGRCQAunqHeftMM+UX2mlsf/8msinWeWy5LZfinAQKs6y6nl18ppIXEZlBPX3D/Pqdeo5UNGEAOamx/NW9i1ixMJmYeTpxTvxLJS8iMo0+OCu+4mI7Z2s7aWjrw8BgzVI7m1ZlY7fND/QUJYSp5EVE/MwwDBrb+ym/0Er5+TZauwYBKMiMZ+OqLNYuTSctUdeyy/RTyYuI+MnAkJtD713lZE07TR39Y5e73X1zNjctStHueJlxKnkRER+4Bkb47btXqG7ooqG1DwNYYI/jLzcUctOiFOLmRwZ6ihLGVPIiItdp1O3hwtVujlQ0cabWicdrsCjbyt03Z3FjYTILM62BnqIIoJIXEZm0+hYXFTUdvHq8gaGR928ru6E0i1tL0shKufaTwEQCRSUvIjKOkVEPb5xs4kxtBxeudmMCFqTHsaE0i5VFyURYzIGeosg1qeRFRD5BV+8wb5918PtTTXS6hklJmMdnb8/j9uXpxEXrOLvMDip5ERFg1O2lsb2Py80uquo7OXvZidtjsDAzns/fuZAbC5N1BzqZdVTyIhK2BofdnKl1Un6hjTO1Hbg9BgAJsVGsXZrOxlXZpFjnBXiWIlOnkheRsNPaNcCv/nCZkzUduD1e4uZHcsfyDBZmxpNnjyMxfq4e4SohQSUvImGhb3CUU8eucOREA2dqnURFWvjU8nRKF6VQkBGP2axSl9AzqZJ//PHHaWxsxGw2Ex0dzbe+9S2Ki4upq6tjx44ddHd3Y7VaKSsrIzc3F2BaxkRErofXa1DT0M0fzjRzorqdUbeXmHlzuG91Lp9akUFCrJ7LLqHNZBiGMdGLent7iY2NBeC1115j7969/OpXv+KRRx7h/vvvZ+vWrbzyyiv84he/4PnnnweYlrHJcjr78Hon/FiTkpwcS3t7r1/eK1wpQ98pw+vX3TfMj16u5FJjD/OiIrjlhlQ+s24h8+eYtCveB1qLvvNnhmazCZvt2vdomNQFnh8UPEBfXx8mkwmn00lVVRWbN28GYPPmzVRVVdHZ2TktYyIik9HRPch/HKrmWz85xtXWXh7ZVMSeL69m+8Yi8jLiVfASViZ9TP6b3/wm77zzDoZh8JOf/ASHw0FqaioWiwUAi8VCSkoKDocDwzD8PpaYmDjpDzXev2qmIjk5duIXybiUoe+U4fhGRj387LUafv7GRUwmE7eUpPHghiJy7XEfep1y9J0y9N1MZTjpkv/Od74DwMsvv8wzzzzDV77ylWmblK+0uz64KEPfKcNrc3u8vHmyiYPvXaWrd5hl+Ta2bywiMW4uwIdyU46+U4a+m8nd9dd9dv1nPvMZdu7cSVpaGq2trXg8HiwWCx6Ph7a2Nux2O4Zh+H1MROQDA0NuztV30tDWy/n6LmqbXR+6aY3OlBd534Ql39/fj8vlGivaN954g/j4eGw2G8XFxezfv5+tW7eyf/9+iouLx3arT8eYiISvnr5hzlx20tzRz+9PNTM04sFsMmG3RbP97kLW3ZgZ6CmKBJ0Jz67v6Ojg8ccfZ3BwELPZTHx8PP/4j//I4sWLqa2tZceOHbhcLuLi4igrKyMvLw9gWsYmS7vrg4sy9F04ZvjB5W/lF9o4e9lJR88QABEWEzfkJrL51lxy0mKZEzH5B8SEY47+pgx9N5O76yd1Cd1so5IPLsrQd+GSodcwqHO4OFrZSnl1G67+ESIjzJTk2chLj6Mwy8oCeywW89Se/BYuOU4nZei7oD4mLyLiL0Mjbmoaerja2kudw0Wdw0V33whzIswszbdx06IUluUnERVpCfRURWYllbyIzKiBITfnr3Ry+pKT8uo2hkc8AKQmRlOQEc+KhcksK7ARPXdOgGcqMvup5EVk2rk9XsrPt/H7U01canLhNQzmRVlYsTCJ20rsLLDHqtRFpoFKXkSmhdvj5XKzi9OXOninsgVX/wjpSfO599ZsSha8f4w9wjK1Y+siMjkqeRHxC8Mw6HQNc6a2g7OXOzl/tYvhEQ8mEyzLT+L25ekszbfptrIiM0glLyI+6Rsc5a0zzbxb2UJTez8AKdZ5rF6cxg25CRRlJxAzT7viRQJBJS8i1214xMO751o4X9/J2bpOhkc8pCfN53PrCijOSSAnTfc2FwkGKnkRmZSBoVHO1XdxttbJ6doOegdGiZk3h5sXpXD78nTy0+MDPUUR+QiVvIhck2EYtPcM8V+v1lB5uROvYRAdFUFJXiK3L0unOCcBk46xiwQtlbyIfExX7/sn0B0ub8DhHMBkgg2lWawsSiYvPW7Kd5wTkZmlkheRMa6BEQ69d5XXTzQyMuolPiaSh9YXsDjPRkbS/EBPT0Suk0peROgbHOVIRRMHjl5haMTD0nwbW25bQE5ajLbaRWYxlbxImBoe8XD+ShflF9o4damDwWE3ywuSeGBdPnabttpFQoFKXiTMDAy5ef1kI7/701Z7dFQEN+QmcN/qXLJTdembSChRyYuEgVG3l8vNPbx2opFTFzvweA1uLEz+0xnyVuZE6ClvIqFIJS8SotweL6cvdfBmRRMXG3sYdXuJsJi5qzST0kUpuq5dJAyo5EVCiNvjpaahm7OXnRw51czwiIf4mEjWrcigKNtKUZZVT3sTCSMqeZEQ4DUMTlS38/Mjl2jvHgLg5uIUVixM5sbCJO2OFwlTKnmRWWxk1MO7lS388VwLFxt7sMVF8fk7F3JrSZoeCiMiKnmR2ai1c4Cf/76WM7VORt1eEmKjePjuQu5Ynq7r2kVkzIQl39XVxT/8wz9w9epVIiMjycnJYffu3SQmJnLq1Cl27tzJ8PAwGRkZ7NmzB5vNBjAtYyLhyus1aGrv43Stk4qadi43u4iKtLBmqZ1l+Ukszdf/IyLycSbDMIzxXtDd3U11dTWrVq0CoKysjJ6eHp5++mk2btzId7/7XUpLS/nRj35EQ0MD3/3ud/F6vX4fux5OZx9e77gfa9KSk2Npb+/1y3uFK2U4NYZh0Owc4MylDl4/2USn6/1j7ZnJ8yktSmHNUjuJcXMDPMvZRWvRd8rQd/7M0Gw2YbPFXHt8ojewWq1jBQ+wfPlympubqaysJCoqitLSUgAeeughDh48CDAtYyLhwDAMGtv62P9uPTv/33t86yfHeOlILZkpMXzxnkX88/+6jd1fWsWWNQtU8CIyoes6Ju/1ennxxRdZv349DoeD9PT0sbHExES8Xi/d3d3TMma1Wic9z/H+VTMVycm6C5ivlOG1jbq91FztoryqhaOVLTS19wGQmhjN3352KTcWpWDXw2H8RmvRd8rQdzOV4XWV/FNPPUV0dDQPP/wwr7766nTNyWfaXR9clOHHDQyNcri8gbOXO2lo68XtMbCYTeSnx/GXGwpZWZSMNSbq/RcbXgBl6Adai75Thr6byd31ky75srIyrly5wnPPPYfZbMZut9Pc3Dw23tnZidlsxmq1TsuYyGznNQyq6js5Ud3OsapWhkY8FGTEc1dpFvnp8RTnJBA9Vxe8iIj/TOovyve//30qKyv58Y9/TGRkJAAlJSUMDQ1x/PhxSktL2bdvH5s2bZq2MZHZanjEwzuVDg69d5X27iEsZhPFOQnce0sOi3ISAj09EQlhE55df/HiRTZv3kxubi5z575/ok9mZiZ79+7l5MmT7Nq160OXuyUlJQFMy9hkaXd9cAnXDIdHPZysaee/Xq2hf8hNdkoM996aw7KCJKLmXN8d6MI1Q39Tjr5Thr6byd31E5b8bKSSDy7hlmFX7zDvnHXwm3frGXV7yUiaz/135LOswIbJZJrSe4ZbhtNFOfpOGfouKI/Ji8j4OnoGeedsCweOXmHU7WVZvo3bl6ezJM9GhEV3oRORmaeSF/FBp2uIc3WdvHPWQU1jDwCLcxP47B355KbFTnnLXUTEH1TyItdpeMRD1ZVO9r97hTqHC4CUhHncf0ceyxcmk26LVrmLSFBQyYtMQqdriNpmFxU17ZypdTIw7CZqjoXNq3MoLUohMzkGs1nFLiLBRSUvcg2GYXC61snPj9TS3NEPQHRUBMW5Cdy6OI0leYl6TruIBDWVvMhHXGzs5mhVK2drnXT0DJGaMI9P35rDwkwri7KtRF7n5W8iIoGikhfhT1vtl5y8eryB81e6iLCYWZKXyKZV2axdatcWu4jMSip5CWujbi9vVjTx1ulmmjr6scZE8tnb81h/YwbRc+cEenoiIj5RyUtYcg2M8Gp5A0cqmugfcpOZPJ8v3rOI25akYTHrmnYRCQ0qeQkbbo+Xqvou3j7roKKmHY/XYHlBEncsT2dp/tTvRiciEqxU8hKyvF6Dy80umjr6OHqulfrWXoZHPMyLsrBmqZ27b8rCbtNz2kUkdKnkJeS4PV5OX+rghVdr6O4bAd6/Wc1tJWkU5yRSkpd43Q+IERGZjVTyEhKGRz20dg5w6mIHr51opG9wFLPJxOfWFbB8YRIp1nm6WY2IhB2VvMxabo+X6oZujpxs4mRNOx88d7A4J4E7/vRgmHlRWuIiEr70F1BmlVG3h+aOASoutvNmRRO9A6NEzbGwcVU22akxFGZaSYybG+hpiogEBZW8BD2v16C1a4D9717hRHUbI24vAMsLkli7zM4NOYlEReoYu4jIR6nkJWgNj3jY/8d6XjvRyPCIB4Dbl9lZvMBGTmoMKQnRgZ2giEiQU8lL0OnpG+bnR2o5XtPO8IiHJXk2VhYlk5ceR2ZyTKCnJyIya6jkJWgYhsGRU8387M1LeL0Gty5O5dbFaRRlJwR6aiIis5JKXgLKMAwczgFqm3p470Ib5+o6uSE3gb/cUKgb1YiI+GjCki8rK+PQoUM0NTXxm9/8hsLCQgDq6urYsWMH3d3dWK1WysrKyM3NnbYxCR29AyOUX2ij8nInje19dPQMAZAQG8XGm7P43LoC3WJWRMQPJnwSx5133skLL7xARkbGh76/a9cutm3bxqFDh9i2bRs7d+6c1jGZ3byGwZWWXl568xJf+z/v8p+Ha2jq6CMnNZbtdxfy7b+6iWcfX82D6xeq4EVE/MRkGIYx8ctg/fr1PPfccxQWFuJ0Otm4cSPHjh3DYrHg8XhYtWoVhw8fxjAMv48lJiZe14dyOvvweif1sSaUnBxLe3uvX94r3BiGwWWHi7fOtvDeuRaG/nSG/A25CfzF2jzy0uNU6JOkdegfytF3ytB3/szQbDZhs137hOQpHZN3OBykpqZisbx/bbLFYiElJQWHw4FhGH4fu96SH+8DT0Vycqxf3y9UGYZB9dUuyqtaOXfZSb3DRf/gKJERZtYsz2BFYTJLCpKwxc8L9FRnJa1D/1COvlOGvpupDEPyxDttyc+crt5h3j7TjMM5QLOzn6utfZhMkJ8ez01FyWQkx7DlUwX0975/3N074laeU6B16B/K0XfK0HdBvyVvt9tpbW3F4/GM7Vpva2vDbrdjGIbfxyS4tHUPUlXfyavlDTicAwDY4uZii4viwfUF3FqSRlx05Njro+fOGSt5ERGZOVMqeZvNRnFxMfv372fr1q3s37+f4uLisd3q0zEmgWUYBkcqmnj9ZBPNHf0ApFjn8cC6fJYXJOlyNxGRIDThiXdPP/00hw8fpqOjg4SEBKxWK7/97W+pra1lx44duFwu4uLiKCsrIy8vD2Baxq6Hdtf7T32Li2NVrZypdeJwDrDAHsfNxSksybORlhg9qce3hnuG/qAM/UM5+k4Z+m4md9dP+uz62UQl7xuP18uRimbePuvgSksvFrOJRdlWShelcPuy9Os+Iz4cM/Q3ZegfytF3ytB3QX9MXkKT1zB4/UQjv367jv4hN2mJ0fyPT+Vzx/J05s+dE+jpiYjIdVLJhznDMHC6hrjY0MPvjl2hsb2f3LRYHl2dy7KFSZh1HbuIyKylkg9TzR39vH3WwdFzLXT3jQCQFD+XR+8tZvWSNJW7iEgIUMmHoWNVrTx/qJqhETeFmVbuW51LTlocuWmxkzqRTkREZgeVfBho7x7kUlMPtU09XGzsoaGtj9y0WB7/TAlJVt19TkQkVKnkQ5RrYIRj51o5Ud1GTWMPAHMjLeSkxvLAunw2lGYRYZnw+UQiIjKLqeRDzOVmFy++XkNtkwuAjOT5fPb2PJbk2chKjdGxdhGRMKKSDwEer5fy820cr26n4mI7MfPmcO8tOdxcnEJ2qh4kISISrlTys5RhGFxudnHsfCt/rGyhf8hNXPQcNpRm8elbc4j9b/eOFxGR8KSSn0U+uH98xaUOGlr76OkfIcJi5obcBFaXpFG6KEW740VEZIxKfhZobOvjRE07x6paaekcIDEuihtyEyjIiOfWkjTmRuo/o4iIfJzaIQh5vF4uXO3m3bMOLjb20NHz/mNa89Pj+OI9i1izxK7r2UVEZEIq+SDR2jnA8eo2ztQ6udLSy4jbS8y8ORRlW1m3IoNVN6SSGDc30NMUEZFZRCUfQMOjHv5wupnfn2oee0Z7blosdyzPICcthpWFKURFWgI8SxERma1U8gFwsqad14430NDWR/+Qm4KMeD5/50JuLEzGFq+tdRER8Q+V/AwZHvFwoqaN1080UufoJW5+JMsXJrFmiZ2i7IRAT09EREKQSn4ajbo9nKvr4mhVC6cudTAy6iUxLorP37mQT63IYE6EbisrIiLTRyXvZ17D4Hx9F0fPtXDsfBtuz/sn0K0usXPLDakUZMbrWnYREZkRKnk/MAyDxvZ+Tta0U36hjeaOfuZEmFl1QworC1MoyUvUw2BERGTGqeSnaNTt4VJjD6drnVRcbKe9ewgTUJAZz6P3FnNjYRLRc+cEepoiIhLGgrLk6+rq2LFjB93d3VitVsrKysjNzQ3onEZGPVy42kVVfRcXrnbR3NGP22MQYTFRnJPIvbfksHxhMvHzdc94EREJDkFZ8rt27WLbtm1s3bqVV155hZ07d/L888/P+DwMw+CKw8Wvf3+Jt844GBx2YzGbWJgZz4bSLBZmWSnKsjIvKihjFBGRMBd07eR0OqmqquKnP/0pAJs3b+app56is7OTxMTEGZ3LS2/WcvC9q1jMJlYWJbNmiZ3CLCuRc3SDGhERCX5BV/IOh4PU1FQslveL1GKxkJKSgsPhmHTJ22wxfplL6eI0MtLiWLs8HVv8PL+8Z7hKTtZz7X2lDP1DOfpOGfpupjIMupL3B6ezD6/X8Pl98lJjWFVip729l/b2Xj/MLDwlJ8cqPx8pQ/9Qjr5Thr7zZ4Zms2ncDdugu67LbrfT2tqKx+MBwOPx0NbWht1uD/DMREREZpegK6tNR38AAAVbSURBVHmbzUZxcTH79+8HYP/+/RQXF8/48XgREZHZLih313/7299mx44d/OhHPyIuLo6ysrJAT0lERGTWCcqSz8/P56WXXgr0NERERGa1oCx5X5nN/r03vL/fLxwpQ98pQ/9Qjr5Thr7zV4YTvY/JMAzfT0MXERGRoBN0J96JiIiIf6jkRUREQpRKXkREJESp5EVEREKUSl5ERCREqeRFRERClEpeREQkRKnkRUREQpRKXkREJESp5EVEREKUSv4a6urqePDBB9m4cSMPPvgg9fX1gZ5S0Fq/fj2bNm1i69atbN26lbfeeguAU6dOsWXLFjZu3Mijjz6K0+kc+5nxxsJBWVkZ69evp6ioiJqamrHvj7fupjoWqq6V4bXWI2hNflRXVxd/8zd/w8aNG7nvvvv4u7/7Ozo7O4GpZxVuOY6XYVFREffdd9/YWqyurh77uTfeeINNmzaxYcMG/v7v/57BwcFJjV03Qz7R9u3bjZdfftkwDMN4+eWXje3btwd4RsFr3bp1RnV19Ye+5/F4jLvuussoLy83DMMw9u7da+zYsWPCsXBRXl5uNDc3fyy78dbdVMdC1bUy/KT1aBhak5+kq6vLOHr06NjX3/ve94yvf/3rU84qHHO8VoaGYRiFhYVGX1/fx36mr6/PWL16tVFXV2cYhmF84xvfMH74wx9OODYVKvlP0NHRYaxcudJwu92GYRiG2+02Vq5caTidzgDPLDh90h/V06dPG5/+9KfHvnY6ncby5csnHAs3/z278dbdVMfCwWRLXmtyYgcPHjS+8IUvTDkr5fjnDA3j2iV/4MAB47HHHhv7+syZM8a999474dhUhOSjZn3lcDhITU3FYrEAYLFYSElJweFwkJiYGODZBacnn3wSwzBYuXIlX/3qV3E4HKSnp4+NJyYm4vV66e7uHnfMarUGYvpBYbx1ZxjGlMbCdb1+dD3GxcVpTU7A6/Xy4osvsn79+ilnFe45/vcMP7B9+3Y8Hg+33347TzzxBJGRkR/LKT09HYfDATDu2FTomLz47IUXXuDXv/41v/jFLzAMg927dwd6ShLGtB6n5qmnniI6OpqHH3440FOZtT6a4ZEjR/jlL3/JCy+8wKVLl9i7d++Mz0kl/wnsdjutra14PB4APB4PbW1t2O32AM8sOH2QS2RkJNu2bePkyZPY7Xaam5vHXtPZ2YnZbMZqtY47Fs7GW3dTHQtHn7QeP/i+1uQnKysr48qVK/zLv/wLZrN5ylmFc44fzRD+vBZjYmJ44IEHrrkWm5ubx1473thUqOQ/gc1mo7i4mP379wOwf/9+iouLw3bX53gGBgbo7e0FwDAMDhw4QHFxMSUlJQwNDXH8+HEA9u3bx6ZNmwDGHQtn4627qY6Fm2utRxh/3YXzmvz+979PZWUle/fuJTIyEph6VuGa4ydl2NPTw9DQEABut5tDhw6NrcW1a9dy9uzZsatg9u3bxz333DPh2FSYDMMwpvzTIay2tpYdO3bgcrmIi4ujrKyMvLy8QE8r6DQ0NPDEE0/g8Xjwer3k5+fzT//0T6SkpHDy5El27drF8PAwGRkZ7Nmzh6SkJIBxx8LB008/zeHDh+no6CAhIQGr1cpvf/vbcdfdVMdC1Sdl+Nxzz11zPcL46y4c1+TFixfZvHkzubm5zJ07F4DMzEz27t075azCLcdrZfjXf/3X7Ny5E5PJhNvtZsWKFXzjG99g/vz5ALz22mvs2bMHr9dLcXEx3/ve94iOjp5w7Hqp5EVEREKUdteLiIiEKJW8iIhIiFLJi4iIhCiVvIiISIhSyYuIiIQolbyIiEiIUsmLiIiEqP8PMFnrBEAwIa0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "salary_plot(describe['25%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "salary_plot(describe['25%'] / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "salary_plot(describe['25%'] / 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На гистограмме видно, что значения столбца *salary* распределены не нормально, а равномерно: клиентов с любым уровнем зарплаты у банка примерно поровну. Несмотря на то, что это лишь оценочные данные, несколько странно, что нет нижней границы: такая тенденция сохраняется вплоть до околонулевого минимума. Нет даже какой-либо \"ступени\".\n",
    "\n",
    "В связи с этим не вполне понятно, что считать аномалией. Не понятно даже, годовая это зарплата или месячная. Не указана размерность. Поскольку речь идёт о странах, входящих в зону евро, скорее всего, зарплата указана в евро.\n",
    "\n",
    "Отбросим совсем уж неправдоподобные значения. На последнем графике виден излом на уровне около 400 евро.\n",
    "\n",
    "Удалим строки со значением *salary* менее 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('salary < 400').count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9984 entries, 0 to 9983\n",
      "Data columns (total 11 columns):\n",
      "score       9984 non-null int64\n",
      "country     9984 non-null object\n",
      "gender      9984 non-null object\n",
      "age         9984 non-null int64\n",
      "tenure      9076 non-null float64\n",
      "balance     9984 non-null float64\n",
      "products    9984 non-null int64\n",
      "card        9984 non-null int64\n",
      "active      9984 non-null int64\n",
      "salary      9984 non-null float64\n",
      "exited      9984 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 858.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.query('salary < 400').index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417.41"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.salary.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбцы *products*, *card*, *active*, *exited*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5077\n",
       "2    4581\n",
       "3     266\n",
       "4      60\n",
       "Name: products, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.products.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7041\n",
       "0    2943\n",
       "Name: card, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.card.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5141\n",
       "0    4843\n",
       "Name: active, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.active.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7951\n",
       "1    2033\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.exited.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё в порядке, аномалий нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим столбец *tenure*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tenure* - единственный столбец, в котором есть пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     381\n",
       "1.0     951\n",
       "2.0     949\n",
       "3.0     927\n",
       "4.0     884\n",
       "5.0     926\n",
       "6.0     881\n",
       "7.0     923\n",
       "8.0     929\n",
       "9.0     881\n",
       "10.0    444\n",
       "Name: tenure, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tenure.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.tenure, bins=11)\n",
    "plt.ylim=(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно описанию данных, в столбце *tenure* содержится информация о количестве недвижимости у клиентов. Однако, данные заставляют в этом усомниться. Если бы это была некая количественная мера недвижимости, то мы бы увидели распределение Пуассона. Или что-то вида y=1/x. Здесь же - равномерное распределение.\n",
    "\n",
    "Посовещавшись с коллегами, с учётом данных, а также принимая во внимание значение слова \"tenure\", принято решение считать этот столбец **сроком, на который выдаётся кредит**. При этом для решения задачи не столь важно, какова размерность - годы или месяцы. Допустим, **годы**.\n",
    "\n",
    "Необходимо решить вопрос с пропусками. Есть три варианта действий:\n",
    "* удалить строки с пропусками;\n",
    "* удалить весь столбец;\n",
    "* заполнить пропуски.\n",
    "\n",
    "Заполнять пропуски некими искусственными значениями (например, медианой или случайными числами от 1 до 10), - возможно, не самая лучшая идея, так как мы не знаем, насколько в итоге критичен этот признак: можно существенно исказить результат, несмотря на возросшие метрики. Модель обучится **хорошо, но не тому**, чему нужно. Этот риск мы никак не уберём, так как **в тестовой выборке** будут также присутствовать объекты с **заполненными** пропусками, и проблема может не проявиться.\n",
    "\n",
    "Удаление части объектов, т.е. уменьшение выборки, негативно отразится на обучении. Но 9% - это всё же **не фатально**. Можно попробовать.\n",
    "\n",
    "Удаление столбца - тоже неплохой вариант. Мы не уменьшаем выборку, а был ли важен этот столбец, покажут метрики уже по факту. В отличие от заполнения пропусков, здесь мы **не рискуем** обучить модель **неправильно**. Модель либо обучится, либо нет, и мы это сразу увидим.\n",
    "\n",
    "Сформируем два датасета:\n",
    "* *data[0]* - удалены строки с пропусками;\n",
    "* *data[1]* - удалён столбец *tenure*.\n",
    "\n",
    "Будем рассматривать их **оба** до тех пор, пока это будет целесообразно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9076 entries, 0 to 9075\n",
      "Data columns (total 11 columns):\n",
      "score       9076 non-null int64\n",
      "country     9076 non-null object\n",
      "gender      9076 non-null object\n",
      "age         9076 non-null int64\n",
      "tenure      9076 non-null float64\n",
      "balance     9076 non-null float64\n",
      "products    9076 non-null int64\n",
      "card        9076 non-null int64\n",
      "active      9076 non-null int64\n",
      "salary      9076 non-null float64\n",
      "exited      9076 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 780.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data.append(df.dropna())\n",
    "data.append(df.dropna(axis=1))\n",
    "\n",
    "data[0].reset_index(drop=True, inplace=True)\n",
    "data[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>products</th>\n",
       "      <th>card</th>\n",
       "      <th>active</th>\n",
       "      <th>salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score country  gender  age    balance  products  card  active     salary  \\\n",
       "0    619  France  Female   42       0.00         1     1       1  101348.88   \n",
       "1    608   Spain  Female   41   83807.86         1     0       1  112542.58   \n",
       "2    502  France  Female   42  159660.80         3     1       0  113931.57   \n",
       "3    699  France  Female   39       0.00         2     0       0   93826.63   \n",
       "4    850   Spain  Female   43  125510.82         1     1       1   79084.10   \n",
       "\n",
       "   exited  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблицы с признаками готовы. Теперь их необходимо преобразовать для машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование признаков, разделение на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим списки с именами категориальных и количественных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = []\n",
    "numerical.append(['score', 'age', 'tenure', 'balance', 'products', 'salary'])\n",
    "numerical.append(['score', 'age', 'balance', 'products', 'salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом категориальном признаке - 2-3 категории. Это позволяет применить технику прямого кодирования One-Hot Encoding (OHE). Размерность таблицы остаётся в разумных пределах. Удалим первые столбцы дамми-переменных во избежание попадания в дамми-ловушку (избыток взаимозависимых признаков).\n",
    "\n",
    "Количественные признаки имеют разный порядок и разный разброс значений. Для корректного обучения необходимо привести такие признаки к одному масштабу. Благодаря масштабированию все признаки будут иметь во время обучения одинаковый вес.\n",
    "\n",
    "Преобразование признаков проведём следующим образом:\n",
    "* выполним прямое кодирование категориальных признаков;\n",
    "* разделим данные на обучающую, валидационную и тестовую выборки в соотношении 3:1:1;\n",
    "* выполним масштабирование количественных признаков в каждой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function transforms categorial and numerical data fitting it for ML purpose\n",
    "# and returns splitted samples: train, valid, test and train+valid for the final training.\n",
    "\n",
    "def data_transform(df, numerical):\n",
    "    df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "    \n",
    "    target = df_ohe.exited\n",
    "    features = df_ohe.drop('exited', axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    features_train_valid, features_test, target_train_valid, target_test = train_test_split(\n",
    "        features, target, test_size=0.2, random_state=r_state)\n",
    "    \n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "        features_train_valid, target_train_valid, test_size=0.25, random_state=r_state)\n",
    "    \n",
    "    scaler.fit(features_train[numerical])\n",
    "    \n",
    "    features_train[numerical] = scaler.transform(features_train[numerical])\n",
    "    features_valid[numerical] = scaler.transform(features_valid[numerical])\n",
    "    \n",
    "    features_train_valid[numerical] = scaler.transform(features_train_valid[numerical])\n",
    "    features_test[numerical] = scaler.transform(features_test[numerical])\n",
    "    \n",
    "    return features_train_valid, target_train_valid, features_test, target_test, \\\n",
    "            features_train, target_train, features_valid, target_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не усложнять код и систему переменных, будем применять функцию *data_transform* не в цикле, а \"вручную\", последовательно для каждого из двух случаев.\n",
    "\n",
    "Проверим, корректно ли работает функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products</th>\n",
       "      <th>card</th>\n",
       "      <th>active</th>\n",
       "      <th>salary</th>\n",
       "      <th>country_Germany</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5492</td>\n",
       "      <td>0.719621</td>\n",
       "      <td>-0.658027</td>\n",
       "      <td>1.032589</td>\n",
       "      <td>-1.230975</td>\n",
       "      <td>0.799311</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.040627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5445</td>\n",
       "      <td>-1.282892</td>\n",
       "      <td>-0.564003</td>\n",
       "      <td>-0.008412</td>\n",
       "      <td>-1.230975</td>\n",
       "      <td>0.799311</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.041367</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4843</td>\n",
       "      <td>-1.054626</td>\n",
       "      <td>0.188185</td>\n",
       "      <td>-0.702413</td>\n",
       "      <td>1.198072</td>\n",
       "      <td>-0.923670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.290184</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8024</td>\n",
       "      <td>1.383667</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>0.685588</td>\n",
       "      <td>0.800229</td>\n",
       "      <td>-0.923670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.067944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4985</td>\n",
       "      <td>0.190460</td>\n",
       "      <td>-0.658027</td>\n",
       "      <td>-1.743414</td>\n",
       "      <td>0.437430</td>\n",
       "      <td>-0.923670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.403377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score       age    tenure   balance  products  card  active  \\\n",
       "5492  0.719621 -0.658027  1.032589 -1.230975  0.799311     1       1   \n",
       "5445 -1.282892 -0.564003 -0.008412 -1.230975  0.799311     1       0   \n",
       "4843 -1.054626  0.188185 -0.702413  1.198072 -0.923670     1       0   \n",
       "8024  1.383667  0.282209  0.685588  0.800229 -0.923670     1       0   \n",
       "4985  0.190460 -0.658027 -1.743414  0.437430 -0.923670     1       0   \n",
       "\n",
       "        salary  country_Germany  country_Spain  gender_Male  \n",
       "5492 -1.040627                0              1            1  \n",
       "5445  1.041367                0              1            1  \n",
       "4843  1.290184                1              0            1  \n",
       "8024 -1.067944                1              0            1  \n",
       "4985 -1.403377                1              0            1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_valid, target_train_valid, features_test, target_test, \\\n",
    "            features_train, target_train, features_valid, target_valid = data_transform(data[0], numerical[0])\n",
    "\n",
    "features_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7260, 11) (7260,) (1816, 11) (1816,) (5445, 11) (5445,) (1815, 11) (1815,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_valid.shape, target_train_valid.shape, features_test.shape, target_test.shape, \\\n",
    "            features_train.shape, target_train.shape, features_valid.shape, target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты соответствуют ожидаемым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод по подготовке данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл с данными открылся нормально, данные - в хорошем состоянии. Пропуски (9,1% строк) имеет только один столбец (*tenure*). Удалены ненужные столбцы. Некоторые столбцы переименованы.\n",
    "\n",
    "На этапе предобработки просмотрены данные всех столбцов. Удалено 16 строк (0,2%), в которых значения *salary* - аномально малые. Пропуски столбца *tenure* обработаны двумя способами: удаление строк с пропусками и удаление столбца целиком. Оба датасета сохранены, и лучший из них будет выявлен позднее.\n",
    "\n",
    "Выполнено преобразование признаков и разделение данных на выборки: тренировочную, валидационную и тестовую в соотношении 3:1:1. Также сохранена выборка \"тренировочная + валидационная\" для обучения модели перед финальным тестированием. Признаки преобразованы следующим образом: категориальные (*country*, *gender*) - методом One-Hot Encoding (OHE); количественные - методом масштабирования.\n",
    "\n",
    "Данные готовы к дальнейшей работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словари, списки, функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_predict_metrics_columns = ['f1', 'recall', 'precision', 'accuracy', 'accuracy_const']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function prints the ratio of pos and neg classes.\n",
    "\n",
    "def class_ratio(target, output=True):\n",
    "    ratio = target[target == 1].count() / target[target == 0].count()\n",
    "    \n",
    "    if output == True:\n",
    "        print(round((ratio), 3))\n",
    "    else:\n",
    "        return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function fits the passed model, forms an array of the predicted values,\n",
    "# computes the metrics and return an array of them.\n",
    "\n",
    "def fit_predict_metrics(model, features_train, target_train, features_valid, target_valid):\n",
    "    # Forming a list of the predicted values\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    predicted_valid_constant = pd.Series(0, index=range(len(predicted_valid)))\n",
    "    \n",
    "    # Computing metrics\n",
    "    array = []\n",
    "    \n",
    "    array.append(f1_score(target_valid, predicted_valid))\n",
    "    array.append(recall_score(target_valid, predicted_valid))\n",
    "    array.append(precision_score(target_valid, predicted_valid))\n",
    "    array.append(accuracy_score(target_valid, predicted_valid))\n",
    "    array.append(accuracy_score(target_valid, predicted_valid_constant))\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function computes the metrics with 'fit_predict_metrics' function for different algorithms\n",
    "# and for different values of hyperparameters. Then it forms the tables of the results.\n",
    "\n",
    "def models_computing_func(features_train, target_train, features_valid, target_valid,\n",
    "                          class_weight=None,\n",
    "                          full_output=False):\n",
    "    \n",
    "    '''\n",
    "    full_output=False - the function outputs only the highest F1-metrics and related essential information\n",
    "    full_output=True  - the function outputs full tables of the metrics computed\n",
    "    '''\n",
    "    \n",
    "    # Dicts of the loop parameters\n",
    "    max_depth_params = {\n",
    "        'min': 4,\n",
    "        'max': 32,\n",
    "        'step': 4\n",
    "    }\n",
    "    \n",
    "    n_estimators_params = {\n",
    "        'min': 10,\n",
    "        'max': 100,\n",
    "        'step': 10\n",
    "    }\n",
    "    \n",
    "    # DecisionTreeClassifier\n",
    "    metrics_row = []\n",
    "    hyperparams = []\n",
    "\n",
    "    for depth in range(max_depth_params['min'], max_depth_params['max']+1, max_depth_params['step']):\n",
    "        metrics_row.append(fit_predict_metrics(DecisionTreeClassifier(max_depth=depth, \n",
    "                                                                      random_state=r_state,\n",
    "                                                                      class_weight=class_weight),\n",
    "                                               features_train, target_train, features_valid, target_valid)\n",
    "                          )\n",
    "        hyperparams.append(depth)\n",
    "\n",
    "    metrics_table_DT = pd.DataFrame(data=metrics_row,\n",
    "                                    index=hyperparams,\n",
    "                                    columns=fit_predict_metrics_columns)\n",
    "    metrics_table_DT.rename_axis('max_depth', axis=0, inplace=True)\n",
    "    metrics_table_DT.reset_index(inplace=True)\n",
    "\n",
    "    # RandomForestClassifier\n",
    "    metrics_row = []\n",
    "    hyperparams = []\n",
    "\n",
    "    for estimators in range(n_estimators_params['min'], n_estimators_params['max']+1, n_estimators_params['step']):\n",
    "        for depth in range(max_depth_params['min'], max_depth_params['max']+1, max_depth_params['step']):\n",
    "            metrics_row.append(fit_predict_metrics(RandomForestClassifier(n_estimators=estimators,\n",
    "                                                                          max_depth=depth,\n",
    "                                                                          random_state=r_state,\n",
    "                                                                          class_weight=class_weight),\n",
    "                                                   features_train, target_train, features_valid, target_valid)\n",
    "                              )\n",
    "            hyperparams.append((estimators, depth))\n",
    "\n",
    "    metrics_table_RF = pd.DataFrame(data=metrics_row,\n",
    "                                    index=pd.MultiIndex.from_tuples(hyperparams, names=('n_estimators', 'max_depth')),\n",
    "                                    columns=fit_predict_metrics_columns)\n",
    "    metrics_table_RF.reset_index(inplace=True)\n",
    "\n",
    "    # LogisticRegression\n",
    "    metrics_row = []\n",
    "\n",
    "    metrics_row.append(fit_predict_metrics(LogisticRegression(random_state=r_state,\n",
    "                                                              class_weight=class_weight),\n",
    "                                           features_train, target_train, features_valid, target_valid)\n",
    "                      )\n",
    "\n",
    "    metrics_table_LR = pd.DataFrame(data=metrics_row,\n",
    "                                    columns=fit_predict_metrics_columns)\n",
    "    \n",
    "    # Table of the best results\n",
    "    metrics_table_best = pd.DataFrame(data=[metrics_table_DT.loc[metrics_table_DT.f1.idxmax],\n",
    "                                            metrics_table_RF.loc[metrics_table_RF.f1.idxmax],\n",
    "                                            metrics_table_LR.loc[metrics_table_LR.f1.idxmax]],\n",
    "                                      index=['Decision Tree', 'Random Forest', 'Logistic Regression'],\n",
    "                                      columns=metrics_table_RF.loc[metrics_table_RF.f1.idxmax].index)\n",
    "    metrics_table_best.fillna('-', inplace=True)\n",
    "\n",
    "    # Output\n",
    "    print('\\nThe highest values of F1-metric and related essential information')\n",
    "    display(metrics_table_best)\n",
    "    \n",
    "    if full_output == True:\n",
    "        with pd.option_context('display.max_rows', 150):\n",
    "            print('\\n\\n\\nDecisionTreeClassifier')\n",
    "            display(metrics_table_DT)\n",
    "            print('\\n\\n\\nRandomForestClassifier')\n",
    "            display(metrics_table_RF)\n",
    "            print('\\n\\n\\nLogisticRegression')\n",
    "            display(metrics_table_LR)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование баланса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под балансом классов понимается соотношение положительных и отрицательных классов целевого признака. В нашем случае - \"0\" и \"1\" столбца *exited*. Если соотношение близко к 1:1, то классы считаются сбалансированными. В противном случае - нет.\n",
    "\n",
    "Вычислим соотношение классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.256\n",
      "0.256\n",
      "0.264\n",
      "0.233\n",
      "0.256\n"
     ]
    }
   ],
   "source": [
    "class_ratio(df.exited)\n",
    "class_ratio(target_train_valid)\n",
    "class_ratio(target_train)\n",
    "class_ratio(target_valid)\n",
    "class_ratio(target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во всех выборках отношение положительного класса к отрицательному - примерно 1:3. Или, по-другому, положительный класс составляет примерно 25% от размера выборки.\n",
    "\n",
    "Выборки с таким соотношением классов считаются **несбалансированными**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование моделей без учёта дисбаланса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели измеряется подходящими метриками.\n",
    "\n",
    "Для моделей-классификаторов в том случае, когда классы целевого признака не сбалансированы, хорошо подходят метрики *Recall* (полнота) и *Precision* (точность). Их необходимо использовать совместно, так как по отдельности они малоинформативны: при росте полноты может падать точность, и - наоборот.\n",
    "\n",
    "Существует также *F1*-мера - среднее гармоническое полноты и точности. *F1*-мера как раз комбинирует эти метрики так, что высокое значение получается, если полнота и точность высокие одновременно. А вот снижается *F1*-мера при снижении хотя бы одной из метрик (если речь идёт о низких значениях).\n",
    "\n",
    "*Accuracy* (тоже точность, но другая: считает долю верно предсказанных классов) для несбалансированных классов не очень годится, так как частый класс угадать случайно более вероятно, чем редкий класс, и даже константная модель будет показывать высокое, на первый взгляд, значение метрики. Чем больше дисбаланс, тем труднее интерпретировать результат.\n",
    "\n",
    "При помощи метрики *Accuracy* желательно проверять модель на адекватность: модель адекватна, если её *Accuracy* выше, чем у константной модели.\n",
    "\n",
    "Рассчитаем указанные метрики для разных алгоритмов (*DecisionTreeClassifier*, *RandomForestClassifier*, *LogisticRegression*) с различными гиперпараметрами. Рассматривать будем, прежде всего, *F1*-меру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование моделей на датасете с удалёнными строками (*data[0]*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем выборки с помощью функции '*data_transform*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid, target_train_valid, features_test, target_test, \\\n",
    "            features_train, target_train, features_valid, target_valid = data_transform(data[0], numerical[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем метрики с помощью функции '*models_computing_func*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The highest values of F1-metric and related essential information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>0.519355</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.581227</td>\n",
       "      <td>0.835813</td>\n",
       "      <td>0.811019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.463557</td>\n",
       "      <td>0.732719</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.811019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.279661</td>\n",
       "      <td>0.192420</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.812672</td>\n",
       "      <td>0.811019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_estimators max_depth        f1    recall  precision  \\\n",
       "Decision Tree                  -         8  0.519355  0.469388   0.581227   \n",
       "Random Forest                100        20  0.567857  0.463557   0.732719   \n",
       "Logistic Regression            -         -  0.279661  0.192420   0.511628   \n",
       "\n",
       "                     accuracy  accuracy_const  \n",
       "Decision Tree        0.835813        0.811019  \n",
       "Random Forest        0.866667        0.811019  \n",
       "Logistic Regression  0.812672        0.811019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_computing_func(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таблицы видно, что наиболее качественная модель по метрике *F1* - Случайный лес. Чуть меньшее значение метрики - у Решающего дерева. Обе модели получились качественнее константной.\n",
    "\n",
    "А вот у Логистической регрессии *F1* примерно вдвое ниже, чем у деревьев, и такая модель оказалась не \"умнее\" константной. Отловила только каждый пятый положительный объект. И при этом имеется почти такое же количество ложноположительных ответов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование моделей на датасете с удалённым столбцом (*data[1]*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведём такие же расчёты на другом датасете.\n",
    "\n",
    "Сформируем выборки с помощью функции '*data_transform*'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid, target_train_valid, features_test, target_test, \\\n",
    "            features_train, target_train, features_valid, target_valid = data_transform(data[1], numerical[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем метрики с помощью функции '*models_computing_func*'.\n",
    "\n",
    "Функция предусматривает возможность просмотреть все рассчитанные метрики. Для этого необходимо передать в функцию параметр *full_output=True*. Важная информация расположена вверху и видна сразу, а для просмотра остальных результатов нужно скроллить ячейку вниз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The highest values of F1-metric and related essential information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>0.570270</td>\n",
       "      <td>0.480638</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.840761</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>0.593923</td>\n",
       "      <td>0.489749</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.852779</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.312605</td>\n",
       "      <td>0.211845</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.795193</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_estimators max_depth        f1    recall  precision  \\\n",
       "Decision Tree                  -         8  0.570270  0.480638   0.700997   \n",
       "Random Forest                 80        28  0.593923  0.489749   0.754386   \n",
       "Logistic Regression            -         -  0.312605  0.211845   0.596154   \n",
       "\n",
       "                     accuracy  accuracy_const  \n",
       "Decision Tree        0.840761         0.78017  \n",
       "Random Forest        0.852779         0.78017  \n",
       "Logistic Regression  0.795193         0.78017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>0.341686</td>\n",
       "      <td>0.824176</td>\n",
       "      <td>0.839259</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.570270</td>\n",
       "      <td>0.480638</td>\n",
       "      <td>0.700997</td>\n",
       "      <td>0.840761</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.498861</td>\n",
       "      <td>0.606648</td>\n",
       "      <td>0.818728</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.521945</td>\n",
       "      <td>0.501139</td>\n",
       "      <td>0.544554</td>\n",
       "      <td>0.798197</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.530425</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.795193</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.517937</td>\n",
       "      <td>0.788182</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.517937</td>\n",
       "      <td>0.788182</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>0.526196</td>\n",
       "      <td>0.517937</td>\n",
       "      <td>0.788182</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth        f1    recall  precision  accuracy  accuracy_const\n",
       "0          4  0.483092  0.341686   0.824176  0.839259         0.78017\n",
       "1          8  0.570270  0.480638   0.700997  0.840761         0.78017\n",
       "2         12  0.547500  0.498861   0.606648  0.818728         0.78017\n",
       "3         16  0.521945  0.501139   0.544554  0.798197         0.78017\n",
       "4         20  0.530425  0.526196   0.534722  0.795193         0.78017\n",
       "5         24  0.522034  0.526196   0.517937  0.788182         0.78017\n",
       "6         28  0.522034  0.526196   0.517937  0.788182         0.78017\n",
       "7         32  0.522034  0.526196   0.517937  0.788182         0.78017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.419411</td>\n",
       "      <td>0.275626</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.832248</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.396355</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.555091</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.715827</td>\n",
       "      <td>0.840260</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.565934</td>\n",
       "      <td>0.469248</td>\n",
       "      <td>0.712803</td>\n",
       "      <td>0.841763</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.562942</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.742537</td>\n",
       "      <td>0.845268</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.451025</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.451025</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.451025</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.432526</td>\n",
       "      <td>0.284738</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.835754</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.558069</td>\n",
       "      <td>0.421412</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.853280</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.462415</td>\n",
       "      <td>0.738182</td>\n",
       "      <td>0.845769</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>0.736462</td>\n",
       "      <td>0.845769</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.589060</td>\n",
       "      <td>0.478360</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.853280</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>0.564539</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.846269</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>0.564539</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.846269</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.564539</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.846269</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.385841</td>\n",
       "      <td>0.248292</td>\n",
       "      <td>0.865079</td>\n",
       "      <td>0.826239</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.546282</td>\n",
       "      <td>0.410023</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.569405</td>\n",
       "      <td>0.457859</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.847772</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.469248</td>\n",
       "      <td>0.743682</td>\n",
       "      <td>0.847772</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0.588402</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.854281</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0.579021</td>\n",
       "      <td>0.471526</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.576976</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.847271</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.576976</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.737589</td>\n",
       "      <td>0.847271</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.406305</td>\n",
       "      <td>0.264237</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.830245</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.547112</td>\n",
       "      <td>0.410023</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>0.576705</td>\n",
       "      <td>0.462415</td>\n",
       "      <td>0.766038</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>0.592179</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.765343</td>\n",
       "      <td>0.853781</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.476082</td>\n",
       "      <td>0.757246</td>\n",
       "      <td>0.851277</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.469248</td>\n",
       "      <td>0.743682</td>\n",
       "      <td>0.847772</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>0.741818</td>\n",
       "      <td>0.846770</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>0.741818</td>\n",
       "      <td>0.846770</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.250569</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.827241</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.543247</td>\n",
       "      <td>0.407745</td>\n",
       "      <td>0.813636</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>0.576705</td>\n",
       "      <td>0.462415</td>\n",
       "      <td>0.766038</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.480638</td>\n",
       "      <td>0.764493</td>\n",
       "      <td>0.853280</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.582633</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.756364</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>0.584145</td>\n",
       "      <td>0.478360</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>28</td>\n",
       "      <td>0.579387</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.745520</td>\n",
       "      <td>0.848773</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.579387</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.745520</td>\n",
       "      <td>0.848773</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.388693</td>\n",
       "      <td>0.250569</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.826740</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>0.550376</td>\n",
       "      <td>0.416856</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>0.578348</td>\n",
       "      <td>0.462415</td>\n",
       "      <td>0.771863</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.476082</td>\n",
       "      <td>0.754513</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>0.587904</td>\n",
       "      <td>0.476082</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.853280</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>0.584828</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>28</td>\n",
       "      <td>0.584828</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>0.584828</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>0.388693</td>\n",
       "      <td>0.250569</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.826740</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>0.557721</td>\n",
       "      <td>0.423690</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.852278</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.457859</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.851277</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>0.576653</td>\n",
       "      <td>0.466970</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>20</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.476082</td>\n",
       "      <td>0.754513</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>0.588398</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>0.587586</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>0.587586</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>0.744755</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.255125</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>0.559880</td>\n",
       "      <td>0.425968</td>\n",
       "      <td>0.816594</td>\n",
       "      <td>0.852779</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>0.575499</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.768061</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.575458</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.849274</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>0.587079</td>\n",
       "      <td>0.476082</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>0.852779</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>80</td>\n",
       "      <td>24</td>\n",
       "      <td>0.591978</td>\n",
       "      <td>0.487472</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.852278</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>0.593923</td>\n",
       "      <td>0.489749</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.852779</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>0.593923</td>\n",
       "      <td>0.489749</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.852779</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.389381</td>\n",
       "      <td>0.250569</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.827241</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>0.561664</td>\n",
       "      <td>0.430524</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.852278</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>0.568571</td>\n",
       "      <td>0.453303</td>\n",
       "      <td>0.762452</td>\n",
       "      <td>0.848773</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>16</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.466970</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.850275</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0.583450</td>\n",
       "      <td>0.473804</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.851277</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>24</td>\n",
       "      <td>0.590028</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>0.752650</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>28</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.754448</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "      <td>32</td>\n",
       "      <td>0.590028</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>0.752650</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.255125</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.560831</td>\n",
       "      <td>0.430524</td>\n",
       "      <td>0.804255</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>0.566572</td>\n",
       "      <td>0.455581</td>\n",
       "      <td>0.749064</td>\n",
       "      <td>0.846770</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.580737</td>\n",
       "      <td>0.466970</td>\n",
       "      <td>0.767790</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.592697</td>\n",
       "      <td>0.480638</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.854782</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0.589708</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.852278</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>28</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.754448</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.587744</td>\n",
       "      <td>0.480638</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.851778</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth        f1    recall  precision  accuracy  \\\n",
       "0             10          4  0.419411  0.275626   0.876812  0.832248   \n",
       "1             10          8  0.536210  0.396355   0.828571  0.849274   \n",
       "2             10         12  0.555091  0.453303   0.715827  0.840260   \n",
       "3             10         16  0.565934  0.469248   0.712803  0.841763   \n",
       "4             10         20  0.562942  0.453303   0.742537  0.845268   \n",
       "5             10         24  0.558533  0.451025   0.733333  0.843265   \n",
       "6             10         28  0.558533  0.451025   0.733333  0.843265   \n",
       "7             10         32  0.558533  0.451025   0.733333  0.843265   \n",
       "8             20          4  0.432526  0.284738   0.899281  0.835754   \n",
       "9             20          8  0.558069  0.421412   0.825893  0.853280   \n",
       "10            20         12  0.568627  0.462415   0.738182  0.845769   \n",
       "11            20         16  0.569832  0.464692   0.736462  0.845769   \n",
       "12            20         20  0.589060  0.478360   0.766423  0.853280   \n",
       "13            20         24  0.564539  0.453303   0.748120  0.846269   \n",
       "14            20         28  0.564539  0.453303   0.748120  0.846269   \n",
       "15            20         32  0.564539  0.453303   0.748120  0.846269   \n",
       "16            30          4  0.385841  0.248292   0.865079  0.826239   \n",
       "17            30          8  0.546282  0.410023   0.818182  0.850275   \n",
       "18            30         12  0.569405  0.457859   0.752809  0.847772   \n",
       "19            30         16  0.575419  0.469248   0.743682  0.847772   \n",
       "20            30         20  0.588402  0.473804   0.776119  0.854281   \n",
       "21            30         24  0.579021  0.471526   0.750000  0.849274   \n",
       "22            30         28  0.576976  0.473804   0.737589  0.847271   \n",
       "23            30         32  0.576976  0.473804   0.737589  0.847271   \n",
       "24            40          4  0.406305  0.264237   0.878788  0.830245   \n",
       "25            40          8  0.547112  0.410023   0.821918  0.850776   \n",
       "26            40         12  0.576705  0.462415   0.766038  0.850776   \n",
       "27            40         16  0.592179  0.482916   0.765343  0.853781   \n",
       "28            40         20  0.584615  0.476082   0.757246  0.851277   \n",
       "29            40         24  0.575419  0.469248   0.743682  0.847772   \n",
       "30            40         28  0.571429  0.464692   0.741818  0.846770   \n",
       "31            40         32  0.571429  0.464692   0.741818  0.846770   \n",
       "32            50          4  0.389381  0.250569   0.873016  0.827241   \n",
       "33            50          8  0.543247  0.407745   0.813636  0.849274   \n",
       "34            50         12  0.576705  0.462415   0.766038  0.850776   \n",
       "35            50         16  0.590210  0.480638   0.764493  0.853280   \n",
       "36            50         20  0.582633  0.473804   0.756364  0.850776   \n",
       "37            50         24  0.584145  0.478360   0.750000  0.850275   \n",
       "38            50         28  0.579387  0.473804   0.745520  0.848773   \n",
       "39            50         32  0.579387  0.473804   0.745520  0.848773   \n",
       "40            60          4  0.388693  0.250569   0.866142  0.826740   \n",
       "41            60          8  0.550376  0.416856   0.809735  0.850275   \n",
       "42            60         12  0.578348  0.462415   0.771863  0.851778   \n",
       "43            60         16  0.583799  0.476082   0.754513  0.850776   \n",
       "44            60         20  0.587904  0.476082   0.768382  0.853280   \n",
       "45            60         24  0.584828  0.482916   0.741259  0.849274   \n",
       "46            60         28  0.584828  0.482916   0.741259  0.849274   \n",
       "47            60         32  0.584828  0.482916   0.741259  0.849274   \n",
       "48            70          4  0.388693  0.250569   0.866142  0.826740   \n",
       "49            70          8  0.557721  0.423690   0.815789  0.852278   \n",
       "50            70         12  0.575107  0.457859   0.773077  0.851277   \n",
       "51            70         16  0.576653  0.466970   0.753676  0.849274   \n",
       "52            70         20  0.583799  0.476082   0.754513  0.850776   \n",
       "53            70         24  0.588398  0.485194   0.747368  0.850776   \n",
       "54            70         28  0.587586  0.485194   0.744755  0.850275   \n",
       "55            70         32  0.587586  0.485194   0.744755  0.850275   \n",
       "56            80          4  0.394366  0.255125   0.868217  0.827742   \n",
       "57            80          8  0.559880  0.425968   0.816594  0.852779   \n",
       "58            80         12  0.575499  0.460137   0.768061  0.850776   \n",
       "59            80         16  0.575458  0.464692   0.755556  0.849274   \n",
       "60            80         20  0.587079  0.476082   0.765568  0.852779   \n",
       "61            80         24  0.591978  0.487472   0.753521  0.852278   \n",
       "62            80         28  0.593923  0.489749   0.754386  0.852779   \n",
       "63            80         32  0.593923  0.489749   0.754386  0.852779   \n",
       "64            90          4  0.389381  0.250569   0.873016  0.827241   \n",
       "65            90          8  0.561664  0.430524   0.807692  0.852278   \n",
       "66            90         12  0.568571  0.453303   0.762452  0.848773   \n",
       "67            90         16  0.578279  0.466970   0.759259  0.850275   \n",
       "68            90         20  0.583450  0.473804   0.759124  0.851277   \n",
       "69            90         24  0.590028  0.485194   0.752650  0.851778   \n",
       "70            90         28  0.588889  0.482916   0.754448  0.851778   \n",
       "71            90         32  0.590028  0.485194   0.752650  0.851778   \n",
       "72           100          4  0.394366  0.255125   0.868217  0.827742   \n",
       "73           100          8  0.560831  0.430524   0.804255  0.851778   \n",
       "74           100         12  0.566572  0.455581   0.749064  0.846770   \n",
       "75           100         16  0.580737  0.466970   0.767790  0.851778   \n",
       "76           100         20  0.592697  0.480638   0.772894  0.854782   \n",
       "77           100         24  0.589708  0.482916   0.757143  0.852278   \n",
       "78           100         28  0.588889  0.482916   0.754448  0.851778   \n",
       "79           100         32  0.587744  0.480638   0.756272  0.851778   \n",
       "\n",
       "    accuracy_const  \n",
       "0          0.78017  \n",
       "1          0.78017  \n",
       "2          0.78017  \n",
       "3          0.78017  \n",
       "4          0.78017  \n",
       "5          0.78017  \n",
       "6          0.78017  \n",
       "7          0.78017  \n",
       "8          0.78017  \n",
       "9          0.78017  \n",
       "10         0.78017  \n",
       "11         0.78017  \n",
       "12         0.78017  \n",
       "13         0.78017  \n",
       "14         0.78017  \n",
       "15         0.78017  \n",
       "16         0.78017  \n",
       "17         0.78017  \n",
       "18         0.78017  \n",
       "19         0.78017  \n",
       "20         0.78017  \n",
       "21         0.78017  \n",
       "22         0.78017  \n",
       "23         0.78017  \n",
       "24         0.78017  \n",
       "25         0.78017  \n",
       "26         0.78017  \n",
       "27         0.78017  \n",
       "28         0.78017  \n",
       "29         0.78017  \n",
       "30         0.78017  \n",
       "31         0.78017  \n",
       "32         0.78017  \n",
       "33         0.78017  \n",
       "34         0.78017  \n",
       "35         0.78017  \n",
       "36         0.78017  \n",
       "37         0.78017  \n",
       "38         0.78017  \n",
       "39         0.78017  \n",
       "40         0.78017  \n",
       "41         0.78017  \n",
       "42         0.78017  \n",
       "43         0.78017  \n",
       "44         0.78017  \n",
       "45         0.78017  \n",
       "46         0.78017  \n",
       "47         0.78017  \n",
       "48         0.78017  \n",
       "49         0.78017  \n",
       "50         0.78017  \n",
       "51         0.78017  \n",
       "52         0.78017  \n",
       "53         0.78017  \n",
       "54         0.78017  \n",
       "55         0.78017  \n",
       "56         0.78017  \n",
       "57         0.78017  \n",
       "58         0.78017  \n",
       "59         0.78017  \n",
       "60         0.78017  \n",
       "61         0.78017  \n",
       "62         0.78017  \n",
       "63         0.78017  \n",
       "64         0.78017  \n",
       "65         0.78017  \n",
       "66         0.78017  \n",
       "67         0.78017  \n",
       "68         0.78017  \n",
       "69         0.78017  \n",
       "70         0.78017  \n",
       "71         0.78017  \n",
       "72         0.78017  \n",
       "73         0.78017  \n",
       "74         0.78017  \n",
       "75         0.78017  \n",
       "76         0.78017  \n",
       "77         0.78017  \n",
       "78         0.78017  \n",
       "79         0.78017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LogisticRegression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.312605</td>\n",
       "      <td>0.211845</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.795193</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1    recall  precision  accuracy  accuracy_const\n",
       "0  0.312605  0.211845   0.596154  0.795193         0.78017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_computing_func(features_train, target_train, features_valid, target_valid,\n",
    "                      full_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время просмотра полной таблицы можно увидеть интересные вещи. Например, несколько раз попадается стопроцентная точность (*Precision* = 1,0) при крайне низкой полноте (*Recall* < 0,1).\n",
    "\n",
    "На этом датасете модели показали более высокие результаты: значения метрики *F1* повысились примерно на 0,03...0,05.\n",
    "\n",
    "У Логистической регрессии появилось небольшое, но заметное отличие от константной модели, и теперь её тоже можно считать адекватной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор лучшего датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получен ответ на вопрос, какой датасет - лучше: с удалёнными строками или с удалённым столбцом. Оказалось, что **более высокое качество** (по метрике *F1*) показывают модели, обученные на датасете **с удалённым столбцом**.\n",
    "\n",
    "Сохранение размера обучающей выборки (отказ от её уменьшения) оказалось важнее для обучения моделей, чем сохранение одного из признаков. Потеря одного признака не столь критична, как потеря 9% объектов.\n",
    "\n",
    "Из трёх рассмотренных алгоритмов наилучшие результаты (по метрике *F1*) показал *RandomForestClassifier* (на обоих датасетах).\n",
    "\n",
    "В **дальнейшем исследовании** будет использоваться только один датасет - тот, в котором **удалён столбец *tenure*** (*data[1]*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9984, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[1]\n",
    "numerical = numerical[1]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>products</th>\n",
       "      <th>card</th>\n",
       "      <th>active</th>\n",
       "      <th>salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score country  gender  age    balance  products  card  active     salary  \\\n",
       "0    619  France  Female   42       0.00         1     1       1  101348.88   \n",
       "1    608   Spain  Female   41   83807.86         1     0       1  112542.58   \n",
       "2    502  France  Female   42  159660.80         3     1       0  113931.57   \n",
       "3    699  France  Female   39       0.00         2     0       0   93826.63   \n",
       "4    850   Spain  Female   43  125510.82         1     1       1   79084.10   \n",
       "\n",
       "   exited  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score', 'age', 'balance', 'products', 'salary']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод по исследованию задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследован баланс классов. Целевой признак не сбалансирован: положительный класс составляет примерно 25% от размера выборки.\n",
    "\n",
    "Исследовались алгоритмы *DecisionTreeClassifier*, *RandomForestClassifier*, *LogisticRegression*. Выполнено обучение моделей с различными значениями гиперпараметров без учёта дисбаланса классов целевого признака. Для каждой модели получены метрики *F1*, *Recall*, *Precision*, *Accuracy*. Выполнена проверка на адекватность путём сравнения *Accuracy* с таковой для константной модели (массив, заполненный только нулями).\n",
    "\n",
    "Одно и то же исследование проведено на двух датасетах:\n",
    "* *data[0]* - удалены строки с пропусками;\n",
    "* *data[1]* - удалён столбец *tenure*.\n",
    "\n",
    "На обоих датасетах модели показали в целом схожие результаты, но *data[1]* оказался лучше. Оказалось **предпочтительнее** сохранить (**не уменьшать**) исходный размер выборки, нежели сохранять все признаки (столбцы).\n",
    "\n",
    "Наибольшее значение метрики *F1* показал алгоритм *RandomForestClassifier*: *F1* = 0,59 при *n_estimators* = 35 и *max_depth* = 20. Чуть меньше - у *DecisionTreeClassifier* (*F1* = 0,57 при *max_depth* = 8). У *LogisticRegression* - меньше почти вдвое (*F1* = 0,31).\n",
    "\n",
    "Другие метрики лучшей модели: *Recall* = 0,49; *Precision* = 0,76. Модель покрыла почти половину положительных объектов. А из тех объектов, которые модель признала положительными, примерно четверть на самом деле таковыми не являются. *Accuracy* = 0,85; *Accuracy* константной модели = 0,78. Количество верно предсказанных объектов на 7 процентных пунктов больше по сравнению с константной моделью: полученная модель адекватна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы улучшить качество модели, необходимо устранить дисбаланс классов целевого признака. Сделать это можно несколькими способами:\n",
    "* взвешиванием классов (аргумент *class_weight*);\n",
    "* изменением размера выборки (upsampling; downsampling).\n",
    "\n",
    "На изменённых этими тремя способами выборках построим различные модели. Возьмём те же алгоритмы, что и на предыдущем этапе (*DecisionTreeClassifier*, *RandomForestClassifier*, *LogisticRegression*), и сравним модели с различными значениями гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function increases the amount of the objects of the positive class or decreases the same of the negative one.\n",
    "\n",
    "def sampling(features, target, method):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    coef = class_ratio(target, output=False)\n",
    "    \n",
    "    if method == 'up':\n",
    "        coef = int(round((1 / coef), 0))\n",
    "        features_sampled = pd.concat([features_zeros] + [features_ones] * coef)\n",
    "        target_sampled = pd.concat([target_zeros] + [target_ones] * coef)\n",
    "    elif method == 'down':\n",
    "        features_sampled = pd.concat([features_zeros.sample(frac=coef, random_state=r_state)] + [features_ones])\n",
    "        target_sampled = pd.concat([target_zeros.sample(frac=coef, random_state=r_state)] + [target_ones])\n",
    "    else:\n",
    "        features_sampled = features\n",
    "        target_sampled = target\n",
    "    \n",
    "    features_sampled, target_sampled = shuffle(features_sampled, target_sampled, random_state=r_state)\n",
    "    \n",
    "    print('total amount original: {}\\nmultiply coefficient: {:.3f}\\namount of pos objects: {}\\\n",
    "          \\namount of neg objects: {}\\ntotal amount {}sampled: {}'\n",
    "          .format(target.count(),\n",
    "                  coef,\n",
    "                  target_sampled[target_sampled == 1].count(),\n",
    "                  target_sampled[target_sampled == 0].count(),\n",
    "                  method,\n",
    "                  target_sampled.count()\n",
    "                 )\n",
    "         )\n",
    "    \n",
    "    return features_sampled, target_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменение весов классов с помощью аргумента *class_weight*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аргумент *class_weight*='balanced' увеличивает вес редкого класса во столько раз, во сколько раз меньше последний представлен в выборке по сравнению с частым классом. Вес редкого класса становится больше единицы, а вес частого - остаётся равен единице.\n",
    "\n",
    "Готовый датасет уже имеется.\n",
    "\n",
    "Сформируем выборки и рассчитаем метрики, как уже делали это выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid, target_train_valid, features_test, target_test, \\\n",
    "            features_train, target_train, features_valid, target_valid = data_transform(data, numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The highest values of F1-metric and related essential information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>0.566604</td>\n",
       "      <td>0.687927</td>\n",
       "      <td>0.481659</td>\n",
       "      <td>0.768653</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.633833</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>0.597980</td>\n",
       "      <td>0.828743</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.506734</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.706560</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_estimators max_depth        f1    recall  precision  \\\n",
       "Decision Tree                  -         8  0.566604  0.687927   0.481659   \n",
       "Random Forest                 20         8  0.633833  0.674260   0.597980   \n",
       "Logistic Regression            -         -  0.506734  0.685649   0.401869   \n",
       "\n",
       "                     accuracy  accuracy_const  \n",
       "Decision Tree        0.768653         0.78017  \n",
       "Random Forest        0.828743         0.78017  \n",
       "Logistic Regression  0.706560         0.78017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_computing_func(features_train, target_train, features_valid, target_valid,\n",
    "                      class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики *F1* **улучшились** у моделей всех трёх алгоритмов, но **не всё так просто**.\n",
    "\n",
    "Лучшие по метрике *F1* модели Решающего дерева и Логистической регрессии имеют качество ниже, чем константная модель, то есть они **не адекватны**! **Сохранил** свою адекватность лишь **Случайный лес**, хотя *Accuracy* здесь ниже, чем до балансировки (было 0,85).\n",
    "\n",
    "По сравнению с несбалансированными классами, здесь у всех моделей значительно **увеличился охват**, но на столько же **уменьшилась точность**. Значения этих метрик как бы \"поменялись местами\".\n",
    "\n",
    "Наиболее **качественная** (и вместе с тем единственно приемлемая) модель - **Случайный лес** (значения метрик и параметров указаны в таблице)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Увеличение размера выборки (upsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличение размера выборки заключается в копировании объектов редкого класса, чтобы в результате их стало примерно столько же, сколько объектов частого класса:\n",
    "* разделим обучающую выборку на положительные и отрицательные объекты;\n",
    "* скопируем положительные объекты несколько раз, добиваясь паритета с отрицательными;\n",
    "* объединим выборки и перемешаем объекты.\n",
    "\n",
    "Создадим соответствующую функцию (её код, как обычно, вынесен в начало данного раздела) и с её помощью выполним преобразование обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total amount original: 5990\n",
      "multiply coefficient: 4.000\n",
      "amount of pos objects: 4824          \n",
      "amount of neg objects: 4784\n",
      "total amount upsampled: 9608\n"
     ]
    }
   ],
   "source": [
    "features_train_upsampled, target_train_upsampled = sampling(features_train, target_train, method='up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общее количество объектов в обучающей выборке стало больше, но - за счёт повторяющихся объектов.\n",
    "\n",
    "Обучим модели и рассчитаем метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The highest values of F1-metric and related essential information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>0.569288</td>\n",
       "      <td>0.692483</td>\n",
       "      <td>0.483307</td>\n",
       "      <td>0.769654</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>0.633371</td>\n",
       "      <td>0.635535</td>\n",
       "      <td>0.631222</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.505863</td>\n",
       "      <td>0.687927</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.704557</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_estimators max_depth        f1    recall  precision  \\\n",
       "Decision Tree                  -         8  0.569288  0.692483   0.483307   \n",
       "Random Forest                 80        12  0.633371  0.635535   0.631222   \n",
       "Logistic Regression            -         -  0.505863  0.687927   0.400000   \n",
       "\n",
       "                     accuracy  accuracy_const  \n",
       "Decision Tree        0.769654         0.78017  \n",
       "Random Forest        0.838257         0.78017  \n",
       "Logistic Regression  0.704557         0.78017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_computing_func(features_train_upsampled, target_train_upsampled, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики *F1* и *Accuracy* практически **не изменились** по сравнению с таковыми при **изменении весов** классов. У Случайного леса изменился баланс между *Recall* и *Precision*.\n",
    "\n",
    "И так же, как и предыдущем случае, получилось с адекватностью моделей: **адекватен** только **Случайный лес**. Остальные - нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение размера выборки (downsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшение размера выборки заключается в удалении из выборки случайно выбранных объектов частого класса так, чтобы количество оставшихся объектов частого класса приблизительно соответствовало количеству объектов редкого класса.\n",
    "\n",
    "Это можно сделать с помощью метода *sample* объекта *DataFrame* (pandas). Уменьшение размера выборки выполняется той же функцией, что и увеличение - *sampling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total amount original: 5990\n",
      "multiply coefficient: 0.252\n",
      "amount of pos objects: 1206          \n",
      "amount of neg objects: 1206\n",
      "total amount downsampled: 2412\n"
     ]
    }
   ],
   "source": [
    "features_train_downsampled, target_train_downsampled = sampling(features_train, target_train, method='down')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общее количество объектов в обучающей выборке стало меньше. Можно даже сказать, что их стало слишком мало - модели могут потерять в качестве из-за недообучения.\n",
    "\n",
    "Обучим модели и рассчитаем метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The highest values of F1-metric and related essential information\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>0.569330</td>\n",
       "      <td>0.706150</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.765148</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>0.604207</td>\n",
       "      <td>0.719818</td>\n",
       "      <td>0.520593</td>\n",
       "      <td>0.792689</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.505068</td>\n",
       "      <td>0.681093</td>\n",
       "      <td>0.401342</td>\n",
       "      <td>0.706560</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_estimators max_depth        f1    recall  precision  \\\n",
       "Decision Tree                  -         4  0.569330  0.706150   0.476923   \n",
       "Random Forest                 40        12  0.604207  0.719818   0.520593   \n",
       "Logistic Regression            -         -  0.505068  0.681093   0.401342   \n",
       "\n",
       "                     accuracy  accuracy_const  \n",
       "Decision Tree        0.765148         0.78017  \n",
       "Random Forest        0.792689         0.78017  \n",
       "Logistic Regression  0.706560         0.78017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_computing_func(features_train_downsampled, target_train_downsampled, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, результаты ухудшились - значения метрик **снизились**, особенно у Случайного леса. Можно лишь добавить, что модель, обученная по алгоритму *Random Forest*, пока ещё качественнее константной модели, а также показывает на валидационной выборке удовлетворительный результат с точки зрения ТЗ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменение порога"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение ROC-кривой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-кривая удобна для исследования метрик *TPR* и *FPR* - долей истинноположительных и ложноположительных ответов соответственно. Эти две метрики взаимосвязаны: у случайной модели они будут стремиться к значениям друг друга, а у идеального классификатора - *TPR*=1 и *FPR*=0.\n",
    "\n",
    "Значения этих метрик изменяются в зависимости от порога (при вероятности выше порога модель относит объект к положительному классу; ниже - к отрицательному). Наиболее качественной модели соответствует точка на ROC-кривой, ближайшая к левому верхнему углу (0; 1). ROC-кривая случайной модели - прямой отрезок из левого нижнего угла (0; 0) в правый верхний (1; 1).\n",
    "\n",
    "Построим ROC-кривую для наиболее качественной модели: *Random Forest*, обученный на увеличенной выборке (upsampling), с гиперпараметрами из таблицы лучших результатов.\n",
    "\n",
    "Создадим модель, обучим её на тренировочной upsampling-выборке, рассчитаем вероятности классов и выделим в отдельный массив вероятности положительного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = RandomForestClassifier(n_estimators=80,\n",
    "                                    max_depth=12,\n",
    "                                    random_state=r_state,\n",
    "                                    class_weight=None)\n",
    "\n",
    "model_best.fit(features_train_upsampled, target_train_upsampled)\n",
    "\n",
    "probabilities_valid = model_best.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим ROC-кривую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.suptitle('ROC-curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-кривая выглядит ожидаемо: возрастает монотонно, без резких всплесков и каких-либо аномалий. ROC-кривая находится выше ROC-кривой случайной модели (пунктирная прямая). Это хорошо: чем выше кривая над прямой, тем качественнее модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование метрики ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порог можно рассматривать как ещё один гиперпараметр: изменять его и тем самым влиять на метрики.\n",
    "\n",
    "Рассчитаем метрики качества для разных порогов. Найдём пороги, дающие самые высокие метрики *F1* и *ROC-AUC* (площадь под ROC-кривой - чем больше, тем лучше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>the highest f1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.633371</td>\n",
       "      <td>0.635535</td>\n",
       "      <td>0.631222</td>\n",
       "      <td>0.765457</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the highest roc_auc</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.697039</td>\n",
       "      <td>0.546429</td>\n",
       "      <td>0.767005</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.78017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     threshold        f1    recall  precision   roc_auc  \\\n",
       "the highest f1             0.5  0.633371  0.635535   0.631222  0.765457   \n",
       "the highest roc_auc        0.4  0.612613  0.697039   0.546429  0.767005   \n",
       "\n",
       "                     accuracy  accuracy_const  \n",
       "the highest f1       0.838257         0.78017  \n",
       "the highest roc_auc  0.806209         0.78017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_threshold = []\n",
    "\n",
    "threshold_range = {\n",
    "    'min': 0.0,\n",
    "    'max': 1.01,\n",
    "    'step': 0.02\n",
    "}\n",
    "\n",
    "for threshold in np.arange(threshold_range['min'], threshold_range['max'], threshold_range['step']):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    predicted_valid_constant = pd.Series(0, index=range(len(predicted_valid)))\n",
    "\n",
    "    array = []\n",
    "    \n",
    "    array.append(f1_score(target_valid, predicted_valid))\n",
    "    array.append(recall_score(target_valid, predicted_valid))\n",
    "    array.append(precision_score(target_valid, predicted_valid))\n",
    "    array.append(roc_auc_score(target_valid, predicted_valid))\n",
    "    array.append(accuracy_score(target_valid, predicted_valid))\n",
    "    array.append(accuracy_score(target_valid, predicted_valid_constant))\n",
    "    \n",
    "    metrics_threshold.append(array)\n",
    "\n",
    "metrics_threshold_list = ['f1', 'recall', 'precision', 'roc_auc', 'accuracy', 'accuracy_const']\n",
    "metrics_threshold_table = pd.DataFrame(data=metrics_threshold,\n",
    "                                       index=np.arange(threshold_range['min'],\n",
    "                                                       threshold_range['max'],\n",
    "                                                       threshold_range['step']),\n",
    "                                       columns=metrics_threshold_list)\n",
    "\n",
    "metrics_threshold_table.rename_axis('threshold', axis=0, inplace=True)\n",
    "metrics_threshold_table.reset_index(inplace=True)\n",
    "\n",
    "metrics_threshold_table_best = pd.DataFrame(data=[metrics_threshold_table.loc[metrics_threshold_table.f1.idxmax],\n",
    "                                                  metrics_threshold_table.loc[metrics_threshold_table.roc_auc.idxmax]],\n",
    "                                            index=['the highest f1', 'the highest roc_auc'],\n",
    "                                            columns=metrics_threshold_table.columns\n",
    "                                           )\n",
    "display(metrics_threshold_table_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики *ROC-AUC* при пороге 0,4 получилось немного более высоким, чем при пороге 0,5 (порог по умолчанию). Однако, **остальные метрики** - наоборот - при пороге 0,4 получаются **заметно хуже**.\n",
    "\n",
    "Таким образом, **наиболее качественная** модель (с самыми высокими метриками *F1* и *AUC-ROC*) получается при пороге, равном 0,5 (**порог по умолчанию**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод по борьбе с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрены следующие способы устранения дисбаланса:\n",
    "* изменение весов классов с помощью аргумента *class_weight*;\n",
    "* увеличение размера выборки (upsampling);\n",
    "* уменьшение размера выборки (downsampling).\n",
    "\n",
    "Также был исследован порог, по которому модель принимает решение об отнесении объекта к тому или иному классу. Его изменение не устраняет дисбаланс напрямую, но влечёт эффект, похожий на взвешивание классов.\n",
    "\n",
    "В первых трёх случаях **адекватными** получились только модели по алгоритму ***Random Forest***. У моделей по алгоритмам Decision Tree и Logistic Regression значение метрики *Accuracy* заметно **ниже**, чем таковое у константной модели. \n",
    "\n",
    "Наиболее высокий результат по метрикам принесло **увеличение размера выборки (upsampling)**: все рассматриваемые метрики получились достаточно высокими (*F1*=0.633; *Recall*=0.636; *Precision*=0.631; *Accuracy*=0.838). При этом большие значения гиперпараметров (количество деревьев - 80, глубина дерева - 12) повышают уверенность в том, что этот результат - не случаен и, вероятно, будет воспроизведён на тестовой выборке.\n",
    "\n",
    "Для лучшей модели была исследована возможность повысить качество в ещё большей степени путём изменения порога. При этом, помимо прочих, рассматривалась метрика *AUC-ROC* - площадь под ROC-кривой. Соответственно, была построена ROC-кривая. В итоге, **самое высокое** качество получилось при пороге, установленном в значение **по умолчанию** - 0.5. Метрика *AUC-ROC*=0.765. При пороге 0,4 значение метрики *AUC-ROC* незначительно повышается (до 0.767), но остальные метрики - заметно снижаются.\n",
    "\n",
    "Таким образом, наиболее качественная модель:\n",
    "* создана по алгоритму *Random Forest*;\n",
    "* дисбаланс классов целевого признака устранён увеличением размера выборки (upsampling);\n",
    "* гиперпараметры: n_estimators=80, max_depth=12 (остальные - по умолчанию);\n",
    "* порог не изменён и равен 0,5 - по умолчанию.\n",
    "\n",
    "Теперь следует протестировать модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим выборку для обучения модели перед тестированием. Возьмём выборку *train_valid*, включающую в себя тренировочную и валидационную выборки, и увеличим её размер, устраняя дисбаланс (метод upsampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total amount original: 7987\n",
      "multiply coefficient: 4.000\n",
      "amount of pos objects: 6580          \n",
      "amount of neg objects: 6342\n",
      "total amount upsampled: 12922\n"
     ]
    }
   ],
   "source": [
    "features_train_valid_upsampled, target_train_valid_upsampled = sampling(features_train_valid, target_train_valid, method='up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и рассчитаем метрики *F1* и *ROC-AUC*.\n",
    "\n",
    "Согласно ТЗ, целевое значение метрики *F1* - не менее 0,59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final testing results\n",
      "F1 score:       0.594\n",
      "ROC-AUC score:  0.758\n",
      "Accuracy score: 0.830\n",
      "Acc.cnst score: 0.806\n"
     ]
    }
   ],
   "source": [
    "model_best.fit(features_train_valid_upsampled, target_train_valid_upsampled)\n",
    "predicted_test = model_best.predict(features_test)\n",
    "predicted_test_constant = pd.Series(0, index=range(len(predicted_test)))\n",
    "\n",
    "print('\\nFinal testing results\\nF1 score:       {:.3f}\\nROC-AUC score:  {:.3f}\\nAccuracy score: {:.3f}\\nAcc.cnst score: {:.3f}'\n",
    "      .format(f1_score(target_test, predicted_test),\n",
    "              roc_auc_score(target_test, predicted_test),\n",
    "              accuracy_score(target_test, predicted_test),\n",
    "              accuracy_score(target_test, predicted_test_constant)\n",
    "             )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод по тестированию модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнена проверка самой качественной модели на тестовой выборке. Значение метрики *F1* меньше на 0.04 по сравнению с метрикой, полученной на валидационной выборке, и составило ***F1*=0.594**. Полученный результат удовлетворяет требованиям ТЗ.\n",
    "\n",
    "Модель - адекватна: значение *Accuracy* - выше, чем у константной модели.\n",
    "\n",
    "Значение метрики *ROC-AUC* значительно выше, чем 0.5, что также говорит о преимуществе по сравнению со случайной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка данных #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этапе предобработки удалены строки с некорректными значениями столбца *salary* (16 строк). В столбце *tenure* принято решение не заполнять пропуски во избежание искажения результатов обучения, а удалить их двумя способами: 1) удалить строки с пропусками; 2) удалить столбец целиком. Лучший из двух полученных датасетов определяется на следующем этапе.\n",
    "\n",
    "Выполнено разделение данных на выборки: тренировочную, валидационную и тестовую в соотношении 3:1:1. Выполнено преобразование признаков: категориальные - методом OHE, количественные - методом масштабирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Исследование задачи #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследован баланс классов: положительный класс составляет 25% от размера выборки.\n",
    "\n",
    "Исследовались алгоритмы *DecisionTreeClassifier*, *RandomForestClassifier*, *LogisticRegression* с различными значениями гиперпараметров без учёта дисбаланса классов целевого признака. Метрики *F1*, *Recall*, *Precision*, *Accuracy* сведены в таблицу. По метрике *F1* выбраны лучшие модели по каждому алгоритму. Выполнена проверка на адекватность по *Accuracy* константной модели.\n",
    "\n",
    "Наиболее высокие результаты показал алгоритм *RandomForestClassifier* на датасете с удалённым полностью столбцом *tenure*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Борьба с дисбалансом #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрены следующие способы устранения дисбаланса:\n",
    "* изменение весов классов с помощью аргумента *class_weight*;\n",
    "* увеличение размера выборки (upsampling);\n",
    "* уменьшение размера выборки (downsampling);\n",
    "* к лучшей модели было применено также изменение порога.\n",
    "\n",
    "Лучшие и вместе с тем единственно адекватные модели были созданы по алгоритму Random Forest. Остальные - утратили адекватность (*Accuracy* ниже, чем у константной модели).\n",
    "\n",
    "Самые высокие значения метрик (прежде всего, *F1*) достигнуты при увеличении размера выборки (upsampling). На валидационной выборке *F1*=0.633. Поскольку гиперпараметры в этом случае приняли довольно большие значения (n_estimators=80, max_depth=12), результат представляется твёрдым (неслучайным), и ожидается его успешное подтверждение на тестовой выборке.\n",
    "\n",
    "Этот результат был достигнут при пороге по умолчанию (0.5); значение метрики *AUC-ROC*=0.765 - тоже самое высокое (если пренебречь небольшой погрешностью)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Тестирование модели #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При проверке на тестовой выборке модель показала значение метрики *F1*, удовлетворяющее требованиям ТЗ: *F1*=0,594. Метрики *Accuracy* и *ROC-AUC* также говорят об адекватности модели и её высоком качестве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Заключение #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель успешно прошла проверку на соответствие требованиям ТЗ и не имеет иных нареканий.\n",
    "\n",
    "Можно передавать модель заказчику для реального применения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
